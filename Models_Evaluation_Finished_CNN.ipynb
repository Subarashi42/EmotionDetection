{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "# For ML data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fer2013_dataset(zip_filename='fer2013_data.zip', extract_path='data'):\n",
    "    \"\"\"Extracts the FER2013 dataset from the provided zip file.\"\"\"\n",
    "    # Create extraction directory if it doesn't exist\n",
    "    if not os.path.exists(extract_path):\n",
    "        os.makedirs(extract_path)\n",
    "        print(f\"Created directory: {extract_path}\")\n",
    "    \n",
    "    # Check if the zip file exists\n",
    "    if not os.path.exists(zip_filename):\n",
    "        print(f\"Error: {zip_filename} not found.\")\n",
    "        print(\"Please ensure the dataset zip file is in the current directory.\")\n",
    "        return False\n",
    "    \n",
    "    # Extract the contents\n",
    "    try:\n",
    "        print(f\"Extracting {zip_filename} to {extract_path}...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"Extraction complete!\")\n",
    "        \n",
    "        # List the extracted contents\n",
    "        extracted_files = os.listdir(extract_path)\n",
    "        print(f\"Extracted {len(extracted_files)} files/directories:\")\n",
    "        for item in extracted_files:\n",
    "            print(f\"- {item}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {zip_filename}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Extract the dataset\n",
    "extract_success = extract_fer2013_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_fer2013_structure(data_path='data'):\n",
    "    \"\"\"Explores and documents the structure of the extracted FER2013 dataset.\"\"\"\n",
    "    print(\"Exploring FER2013 dataset structure...\")\n",
    "    \n",
    "    # Define expected emotion categories\n",
    "    emotion_categories = {\n",
    "        0: 'Angry', 1: 'Disgust', 2: 'Fear', \n",
    "        3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'\n",
    "    }\n",
    "    \n",
    "    # Check for fer2013.csv (the main dataset file)\n",
    "    csv_path = os.path.join(data_path, 'fer2013.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"\\nFound main dataset file: {csv_path}\")\n",
    "        \n",
    "        # Load and inspect CSV file\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Check for expected columns\n",
    "        if 'pixels' in df.columns and 'emotion' in df.columns:\n",
    "            print(\"\\nDataset format is as expected with 'pixels' and 'emotion' columns.\")\n",
    "            \n",
    "            # Display emotion distribution\n",
    "            emotion_counts = df['emotion'].value_counts().sort_index()\n",
    "            print(\"\\nEmotion distribution:\")\n",
    "            total_images = len(df)\n",
    "            \n",
    "            for emotion_idx, count in emotion_counts.items():\n",
    "                emotion_name = emotion_categories.get(emotion_idx, f\"Unknown ({emotion_idx})\")\n",
    "                percentage = (count / total_images) * 100\n",
    "                print(f\"- {emotion_name}: {count} images ({percentage:.2f}%)\")\n",
    "            \n",
    "            return df\n",
    "    \n",
    "    # Check for alternative dataset formats (image directories)\n",
    "    for subdir in ['train', 'test', 'val']:\n",
    "        subdir_path = os.path.join(data_path, subdir)\n",
    "        if os.path.exists(subdir_path) and os.path.isdir(subdir_path):\n",
    "            print(f\"\\nFound {subdir} directory: {subdir_path}\")\n",
    "            \n",
    "            # Check for emotion subdirectories\n",
    "            emotion_dirs = [d for d in os.listdir(subdir_path) \n",
    "                           if os.path.isdir(os.path.join(subdir_path, d))]\n",
    "            \n",
    "            print(f\"Contains {len(emotion_dirs)} subdirectories:\")\n",
    "            for emotion_dir in emotion_dirs:\n",
    "                dir_path = os.path.join(subdir_path, emotion_dir)\n",
    "                num_images = len([f for f in os.listdir(dir_path) \n",
    "                                 if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "                print(f\"- {emotion_dir}: {num_images} images\")\n",
    "    \n",
    "    print(\"\\nDataset exploration complete.\")\n",
    "    return None\n",
    "\n",
    "# Explore the dataset structure\n",
    "fer_df = explore_fer2013_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fer2013_data(data_path='data', df=None):\n",
    "    \"\"\"Loads the FER2013 dataset into memory.\"\"\"\n",
    "    # Define emotion mapping\n",
    "    emotion_map = {\n",
    "        0: 'Angry', 1: 'Disgust', 2: 'Fear', \n",
    "        3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'\n",
    "    }\n",
    "    \n",
    "    # First, try loading from CSV\n",
    "    csv_path = os.path.join(data_path, 'fer2013.csv')\n",
    "    if df is None and os.path.exists(csv_path):\n",
    "        print(f\"Loading data from {csv_path}...\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "    \n",
    "    if df is not None and 'pixels' in df.columns and 'emotion' in df.columns:\n",
    "        print(\"Processing data from DataFrame...\")\n",
    "        \n",
    "        # Parse string pixel values into numpy arrays\n",
    "        print(\"Converting pixel strings to image arrays...\")\n",
    "        X = []\n",
    "        \n",
    "        # Simple progress tracking\n",
    "        total_rows = len(df)\n",
    "        print_intervals = [int(total_rows * i / 10) for i in range(1, 11)]\n",
    "        \n",
    "        for i, pixel_str in enumerate(df['pixels']):\n",
    "            # Simple progress reporting\n",
    "            if i in print_intervals:\n",
    "                print(f\"Progress: {i}/{total_rows} images ({i/total_rows*100:.1f}%)\")\n",
    "                \n",
    "            pixels = [int(p) for p in pixel_str.split()]\n",
    "            X.append(np.array(pixels).reshape(48, 48))\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = df['emotion'].values\n",
    "        \n",
    "        print(f\"Loaded {len(X)} images with shape {X[0].shape}\")\n",
    "        return X, y, emotion_map\n",
    "    \n",
    "    # If CSV loading fails, try loading from image directories\n",
    "    print(\"CSV loading failed, checking for image directories...\")\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    total_images = 0\n",
    "    \n",
    "    # First count total images\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_dir = os.path.join(data_path, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "        \n",
    "        for emotion_idx, emotion_name in emotion_map.items():\n",
    "            # Try different directory naming conventions\n",
    "            for dir_name in [emotion_name.lower(), str(emotion_idx)]:\n",
    "                emotion_dir = os.path.join(split_dir, dir_name)\n",
    "                if os.path.exists(emotion_dir):\n",
    "                    total_images += len([f for f in os.listdir(emotion_dir) \n",
    "                                        if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    \n",
    "    print(f\"Found {total_images} images in directories. Loading...\")\n",
    "    processed_images = 0\n",
    "    print_intervals = [int(total_images * i / 10) for i in range(1, 11)]\n",
    "    \n",
    "    # Load images from directories\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_dir = os.path.join(data_path, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "        \n",
    "        print(f\"Loading images from {split_dir}...\")\n",
    "        \n",
    "        for emotion_idx, emotion_name in emotion_map.items():\n",
    "            # Try different directory naming conventions\n",
    "            for dir_name in [emotion_name.lower(), str(emotion_idx)]:\n",
    "                emotion_dir = os.path.join(split_dir, dir_name)\n",
    "                if not os.path.exists(emotion_dir):\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Loading {emotion_name} images...\")\n",
    "                for img_file in os.listdir(emotion_dir):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        img_path = os.path.join(emotion_dir, img_file)\n",
    "                        img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "                        img_resized = img.resize((48, 48))\n",
    "                        img_array = np.array(img_resized)\n",
    "                        X.append(img_array)\n",
    "                        y.append(emotion_idx)\n",
    "                        \n",
    "                        processed_images += 1\n",
    "                        if processed_images in print_intervals:\n",
    "                            print(f\"Progress: {processed_images}/{total_images} images ({processed_images/total_images*100:.1f}%)\")\n",
    "    \n",
    "    if len(X) > 0:\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        print(f\"Loaded {len(X)} images with shape {X[0].shape}\")\n",
    "        return X, y, emotion_map\n",
    "    \n",
    "    print(\"Failed to load dataset. Please check the dataset structure.\")\n",
    "    return None, None, emotion_map\n",
    "\n",
    "# Load the dataset\n",
    "X, y, emotion_map = load_fer2013_data(df=fer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "if X is not None and y is not None:\n",
    "    print(\"\\nDataset Overview:\")\n",
    "    print(f\"Total images: {len(X)}\")\n",
    "    print(f\"Image dimensions: {X[0].shape}\")\n",
    "    print(f\"Label distribution:\")\n",
    "    \n",
    "    unique_labels, counts = np.unique(y, return_counts=True)\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        emotion_name = emotion_map[label]\n",
    "        percentage = (count / len(y)) * 100\n",
    "        print(f\"- {emotion_name}: {count} images ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Memory usage estimation\n",
    "    memory_usage_mb = X.nbytes / (1024 * 1024)\n",
    "    print(f\"\\nEstimated memory usage for image data: {memory_usage_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_emotion_samples(X, y, emotion_map, samples_per_emotion=3):\n",
    "    \"\"\"Visualizes sample images from each emotion category.\"\"\"\n",
    "    if X is None or y is None:\n",
    "        print(\"No data available to visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Get all unique emotion labels\n",
    "    unique_emotions = sorted(np.unique(y))\n",
    "    num_emotions = len(unique_emotions)\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(num_emotions, samples_per_emotion, \n",
    "                            figsize=(samples_per_emotion*3, num_emotions*2.5))\n",
    "    \n",
    "    # For each emotion, select random samples\n",
    "    for i, emotion_idx in enumerate(unique_emotions):\n",
    "        # Get indices of all images with this emotion\n",
    "        emotion_indices = np.where(y == emotion_idx)[0]\n",
    "        \n",
    "        # Select random samples\n",
    "        if len(emotion_indices) < samples_per_emotion:\n",
    "            sample_indices = emotion_indices\n",
    "        else:\n",
    "            sample_indices = np.random.choice(emotion_indices, samples_per_emotion, replace=False)\n",
    "        \n",
    "        # Display each sample\n",
    "        for j, idx in enumerate(sample_indices):\n",
    "            ax = axes[i, j] if num_emotions > 1 else axes[j]\n",
    "            ax.imshow(X[idx], cmap='gray')\n",
    "            \n",
    "            if j == 0:  # Only add emotion label to first sample in row\n",
    "                ax.set_ylabel(emotion_map[emotion_idx], fontsize=12)\n",
    "            \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Sample Images from Each Emotion Category', y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample images\n",
    "visualize_emotion_samples(X, y, emotion_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, test_size=0.1, val_size=0.1):\n",
    "    \"\"\"Splits the dataset into training, validation, and test sets.\"\"\"\n",
    "    if X is None or y is None:\n",
    "        print(\"No data available to split.\")\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    # First split: separate test set\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Second split: separate validation set from remaining data\n",
    "    val_size_adjusted = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(\"Dataset split complete:\")\n",
    "    print(f\"Training set: {len(X_train)} images ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "    print(f\"Validation set: {len(X_val)} images ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "    print(f\"Test set: {len(X_test)} images ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "    \n",
    "    # Verify class distribution is preserved\n",
    "    def print_distribution(name, labels):\n",
    "        print(f\"\\n{name} set emotion distribution:\")\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        for u, c in zip(unique, counts):\n",
    "            print(f\"- {emotion_map[u]}: {c} images ({c/len(labels)*100:.1f}%)\")\n",
    "    \n",
    "    print_distribution(\"Training\", y_train)\n",
    "    print_distribution(\"Validation\", y_val)\n",
    "    print_distribution(\"Test\", y_test)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_set(X_test, y_test, save_dir='data/test_set'):\n",
    "    \"\"\"Saves the test set separately to avoid data leakage.\"\"\"\n",
    "    if X_test is None or y_test is None:\n",
    "        return\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Save test data\n",
    "    np.save(os.path.join(save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(save_dir, 'y_test.npy'), y_test)\n",
    "    \n",
    "    print(f\"\\nTest set saved to {save_dir}\")\n",
    "    print(\"This test set should only be used for final model evaluation.\")\n",
    "\n",
    "# Save the test set\n",
    "save_test_set(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \"\"\"Performs basic preprocessing on the data for modeling.\"\"\"\n",
    "    if X_train is None or y_train is None:\n",
    "        print(\"No data available to preprocess.\")\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    X_train_norm = X_train.astype('float32') / 255.0\n",
    "    X_val_norm = X_val.astype('float32') / 255.0\n",
    "    X_test_norm = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Add channel dimension for CNN models (height, width, channels)\n",
    "    X_train_cnn = X_train_norm.reshape(X_train_norm.shape[0], 48, 48, 1)\n",
    "    X_val_cnn = X_val_norm.reshape(X_val_norm.shape[0], 48, 48, 1)\n",
    "    X_test_cnn = X_test_norm.reshape(X_test_norm.shape[0], 48, 48, 1)\n",
    "    \n",
    "    # One-hot encode the labels for categorical crossentropy loss\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_onehot = to_categorical(y_train, num_classes)\n",
    "    y_val_onehot = to_categorical(y_val, num_classes)\n",
    "    y_test_onehot = to_categorical(y_test, num_classes)\n",
    "    \n",
    "    print(\"Preprocessing complete:\")\n",
    "    print(f\"X_train shape: {X_train_cnn.shape}\")\n",
    "    print(f\"X_val shape: {X_val_cnn.shape}\")\n",
    "    print(f\"X_test shape: {X_test_cnn.shape}\")\n",
    "    print(f\"y_train shape: {y_train_onehot.shape}\")\n",
    "    \n",
    "    return X_train_cnn, X_val_cnn, X_test_cnn, y_train_onehot, y_val_onehot, y_test_onehot\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_cnn, X_val_cnn, X_test_cnn, y_train_onehot, y_val_onehot, y_test_onehot = preprocess_data(\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(X_train, X_val, y_train, y_val, save_dir='data/processed'):\n",
    "    \"\"\"Saves the preprocessed data for future use.\"\"\"\n",
    "    if X_train is None or y_train is None:\n",
    "        return\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Save preprocessed data\n",
    "    np.save(os.path.join(save_dir, 'X_train_cnn.npy'), X_train)\n",
    "    np.save(os.path.join(save_dir, 'X_val_cnn.npy'), X_val)\n",
    "    np.save(os.path.join(save_dir, 'y_train_onehot.npy'), y_train)\n",
    "    np.save(os.path.join(save_dir, 'y_val_onehot.npy'), y_val)\n",
    "    \n",
    "    print(f\"\\nPreprocessed data saved to {save_dir}\")\n",
    "\n",
    "# Save the preprocessed data\n",
    "save_processed_data(X_train_cnn, X_val_cnn, y_train_onehot, y_val_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Feature Engineering and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1 Enhanced Feature Extraction\n",
    "\n",
    "def extract_facial_features(images):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from facial images for emotion classification.\n",
    "    \n",
    "    Args:\n",
    "        images: Array of facial images\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing extracted features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    feature_groups = {}  # Track feature groups for analysis\n",
    "    \n",
    "    for img in images:\n",
    "        try:\n",
    "            # Define facial regions with more precise areas for better emotion differentiation\n",
    "            regions = {\n",
    "                'left_eye': img[12:24, 12:24],\n",
    "                'right_eye': img[12:24, 24:36],\n",
    "                'mouth': img[30:42, 18:30],\n",
    "                'nose': img[24:30, 18:30],\n",
    "                'forehead': img[0:12, 12:36],\n",
    "                'left_cheek': img[24:36, 0:18],\n",
    "                'right_cheek': img[24:36, 30:48],\n",
    "                'eyebrows': img[8:16, 12:36],        # Important for anger/disgust\n",
    "                'upper_mouth': img[28:34, 18:30],    # Important for surprise/fear\n",
    "                'lower_mouth': img[34:42, 18:30],    # Important for distinguishing happiness\n",
    "                'between_eyes': img[16:24, 20:28]    # Important for fear/surprise differentiation\n",
    "            }\n",
    "            \n",
    "            # Initialize feature dictionary\n",
    "            img_features = {}\n",
    "            \n",
    "            # --- Global statistical features ---\n",
    "            feature_groups['global_stats'] = []\n",
    "            \n",
    "            img_features['mean_intensity'] = np.mean(img)\n",
    "            img_features['median_intensity'] = np.median(img)\n",
    "            img_features['std_intensity'] = np.std(img)\n",
    "            img_features['min_intensity'] = np.min(img)\n",
    "            img_features['max_intensity'] = np.max(img)\n",
    "            img_features['intensity_range'] = img_features['max_intensity'] - img_features['min_intensity']\n",
    "            \n",
    "            feature_groups['global_stats'].extend(['mean_intensity', 'median_intensity', 'std_intensity', \n",
    "                                                    'min_intensity', 'max_intensity', 'intensity_range'])\n",
    "            \n",
    "            # --- Histogram features ---\n",
    "            feature_groups['histogram'] = []\n",
    "            \n",
    "            hist, bins = np.histogram(img, bins=16, range=(0, 256))\n",
    "            hist = hist / np.sum(hist)  # Normalize\n",
    "            for i, h in enumerate(hist):\n",
    "                img_features[f'hist_bin_{i}'] = h\n",
    "                feature_groups['histogram'].append(f'hist_bin_{i}')\n",
    "            \n",
    "            # --- Edge-based features ---\n",
    "            feature_groups['edge'] = []\n",
    "            \n",
    "            sobel_h = ndimage.sobel(img, axis=0)\n",
    "            sobel_v = ndimage.sobel(img, axis=1)\n",
    "            magnitude = np.sqrt(sobel_h**2 + sobel_v**2)\n",
    "            img_features['edge_mean'] = np.mean(magnitude)\n",
    "            img_features['edge_std'] = np.std(magnitude)\n",
    "            img_features['edge_max'] = np.max(magnitude)\n",
    "            \n",
    "            feature_groups['edge'].extend(['edge_mean', 'edge_std', 'edge_max'])\n",
    "            \n",
    "            # Direction of edges (useful for mouth curvature)\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                direction = np.arctan2(sobel_v, sobel_h) * 180 / np.pi\n",
    "                direction = np.nan_to_num(direction)\n",
    "            \n",
    "            # Count edges in different directions\n",
    "            direction_bins = np.linspace(-180, 180, 9)\n",
    "            hist_dir, _ = np.histogram(direction, bins=direction_bins)\n",
    "            hist_dir = hist_dir / np.sum(hist_dir)\n",
    "            for i, h in enumerate(hist_dir):\n",
    "                img_features[f'edge_dir_{i}'] = h\n",
    "                feature_groups['edge'].append(f'edge_dir_{i}')\n",
    "            \n",
    "            # --- Regional features ---\n",
    "            feature_groups['regional'] = []\n",
    "            \n",
    "            for region_name, region in regions.items():\n",
    "                # Regional statistical features\n",
    "                img_features[f'{region_name}_mean'] = np.mean(region)\n",
    "                img_features[f'{region_name}_std'] = np.std(region)\n",
    "                img_features[f'{region_name}_median'] = np.median(region)\n",
    "                \n",
    "                feature_groups['regional'].extend([f'{region_name}_mean', f'{region_name}_std', f'{region_name}_median'])\n",
    "                \n",
    "                # Regional edge features\n",
    "                region_sobel_h = ndimage.sobel(region, axis=0)\n",
    "                region_sobel_v = ndimage.sobel(region, axis=1)\n",
    "                region_magnitude = np.sqrt(region_sobel_h**2 + region_sobel_v**2)\n",
    "                img_features[f'{region_name}_edge_mean'] = np.mean(region_magnitude)\n",
    "                img_features[f'{region_name}_edge_std'] = np.std(region_magnitude)\n",
    "                \n",
    "                feature_groups['regional'].extend([f'{region_name}_edge_mean', f'{region_name}_edge_std'])\n",
    "            \n",
    "            # --- Emotion-specific features ---\n",
    "            feature_groups['emotion_specific'] = []\n",
    "            \n",
    "            # Mouth shape features (important for distinguishing emotions)\n",
    "            mouth_region = regions['mouth']\n",
    "            if mouth_region.size > 0:\n",
    "                # Measure mouth openness (vertical variance)\n",
    "                mouth_vertical_profile = np.mean(mouth_region, axis=1)\n",
    "                img_features['mouth_openness'] = np.var(mouth_vertical_profile)\n",
    "                \n",
    "                # Measure mouth width/curvature (horizontal variance)\n",
    "                mouth_horizontal_profile = np.mean(mouth_region, axis=0)\n",
    "                img_features['mouth_width_var'] = np.var(mouth_horizontal_profile)\n",
    "                \n",
    "                # Enhanced smile detection (higher values at corners than center)\n",
    "                if mouth_horizontal_profile.size > 2:\n",
    "                    left_corner = np.mean(mouth_horizontal_profile[:4])\n",
    "                    right_corner = np.mean(mouth_horizontal_profile[-4:])\n",
    "                    center = np.mean(mouth_horizontal_profile[4:-4])\n",
    "                    img_features['smile_metric'] = (left_corner + right_corner) / (2 * center + 1e-10)\n",
    "                    \n",
    "                    # Smile asymmetry (helps distinguish genuine from fake smiles)\n",
    "                    img_features['smile_asymmetry'] = np.abs(left_corner - right_corner) / (left_corner + right_corner + 1e-10)\n",
    "                else:\n",
    "                    img_features['smile_metric'] = 0\n",
    "                    img_features['smile_asymmetry'] = 0\n",
    "            else:\n",
    "                img_features['mouth_openness'] = 0\n",
    "                img_features['mouth_width_var'] = 0\n",
    "                img_features['smile_metric'] = 0\n",
    "                img_features['smile_asymmetry'] = 0\n",
    "            \n",
    "            feature_groups['emotion_specific'].extend(['mouth_openness', 'mouth_width_var', 'smile_metric', 'smile_asymmetry'])\n",
    "            \n",
    "            # Eye features (important for surprise/fear)\n",
    "            left_eye_region = regions['left_eye']\n",
    "            right_eye_region = regions['right_eye']\n",
    "            if left_eye_region.size > 0 and right_eye_region.size > 0:\n",
    "                # Eye openness detection\n",
    "                left_eye_vertical = np.mean(left_eye_region, axis=1)\n",
    "                right_eye_vertical = np.mean(right_eye_region, axis=1)\n",
    "                img_features['eye_openness'] = (np.var(left_eye_vertical) + np.var(right_eye_vertical)) / 2\n",
    "                \n",
    "                # Eye asymmetry (important for certain emotions)\n",
    "                img_features['eye_asymmetry'] = np.abs(np.var(left_eye_vertical) - np.var(right_eye_vertical)) / (np.var(left_eye_vertical) + np.var(right_eye_vertical) + 1e-10)\n",
    "            else:\n",
    "                img_features['eye_openness'] = 0\n",
    "                img_features['eye_asymmetry'] = 0\n",
    "            \n",
    "            feature_groups['emotion_specific'].extend(['eye_openness', 'eye_asymmetry'])\n",
    "            \n",
    "            # Eyebrow features (important for anger/disgust)\n",
    "            eyebrow_region = regions['eyebrows']\n",
    "            if eyebrow_region.size > 0:\n",
    "                # Measure eyebrow \"furrowing\"\n",
    "                eyebrow_horizontal = np.mean(eyebrow_region, axis=0)\n",
    "                eyebrow_vertical = np.mean(eyebrow_region, axis=1)\n",
    "                img_features['eyebrow_var_h'] = np.var(eyebrow_horizontal)\n",
    "                img_features['eyebrow_var_v'] = np.var(eyebrow_vertical)\n",
    "                \n",
    "                # Eyebrow center depression (for anger)\n",
    "                midpoint = len(eyebrow_horizontal) // 2\n",
    "                if midpoint > 2:\n",
    "                    center = np.mean(eyebrow_horizontal[midpoint-2:midpoint+2])\n",
    "                    sides = (np.mean(eyebrow_horizontal[:4]) + np.mean(eyebrow_horizontal[-4:])) / 2\n",
    "                    img_features['eyebrow_depression'] = (sides - center) / (sides + 1e-10)\n",
    "                else:\n",
    "                    img_features['eyebrow_depression'] = 0\n",
    "            else:\n",
    "                img_features['eyebrow_var_h'] = 0\n",
    "                img_features['eyebrow_var_v'] = 0\n",
    "                img_features['eyebrow_depression'] = 0\n",
    "            \n",
    "            feature_groups['emotion_specific'].extend(['eyebrow_var_h', 'eyebrow_var_v', 'eyebrow_depression'])\n",
    "            \n",
    "            # --- Symmetry features ---\n",
    "            feature_groups['symmetry'] = []\n",
    "            \n",
    "            flipped = np.fliplr(img)\n",
    "            img_features['asymmetry_score'] = np.mean(np.abs(img - flipped))\n",
    "            feature_groups['symmetry'].append('asymmetry_score')\n",
    "            \n",
    "            # Validate all features\n",
    "            for key, value in list(img_features.items()):\n",
    "                if np.isnan(value) or np.isinf(value):\n",
    "                    img_features[key] = 0.0  # Replace with safe default\n",
    "            \n",
    "            features.append(img_features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features: {str(e)}\")\n",
    "            # Add default feature set if extraction fails\n",
    "            default_features = {'mean_intensity': 0.0, 'median_intensity': 0.0, 'std_intensity': 0.0}\n",
    "            features.append(default_features)\n",
    "    \n",
    "    # Convert to DataFrame with validation\n",
    "    if not features:\n",
    "        return pd.DataFrame(), feature_groups\n",
    "    \n",
    "    feature_df = pd.DataFrame(features)\n",
    "    \n",
    "    # Final validation\n",
    "    feature_df = feature_df.replace([np.inf, -np.inf], 0.0)\n",
    "    feature_df = feature_df.fillna(0.0)\n",
    "    \n",
    "    return feature_df, feature_groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Create Emotion Mappimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2 Create 5-Class Emotion Mapping\n",
    "\n",
    "def map_emotions_to_five_classes(emotion_label):\n",
    "    \"\"\"\n",
    "    Maps the 7 original emotion classes to 5 broader categories:\n",
    "    0: Positive (originally Happy)\n",
    "    1: Negative-High Arousal (originally Angry, Disgust)\n",
    "    2: Negative-Low Arousal (originally Sad, Fear)\n",
    "    3: Surprise (remains the same)\n",
    "    4: Neutral (remains the same)\n",
    "    \"\"\"\n",
    "    emotion_mapping = {\n",
    "        0: 1,  # Angry -> Negative-High Arousal\n",
    "        1: 1,  # Disgust -> Negative-High Arousal\n",
    "        2: 2,  # Fear -> Negative-Low Arousal\n",
    "        3: 0,  # Happy -> Positive\n",
    "        4: 2,  # Sad -> Negative-Low Arousal\n",
    "        5: 3,  # Surprise -> Surprise (maintains its own category)\n",
    "        6: 4,  # Neutral -> Neutral\n",
    "    }\n",
    "    return emotion_mapping[emotion_label]\n",
    "\n",
    "def create_five_class_mapping(y_train, y_val, y_test=None):\n",
    "    \"\"\"\n",
    "    Create 5-class emotion mappings from the original 7-class labels.\n",
    "    \n",
    "    Args:\n",
    "        y_train, y_val, y_test: Original 7-class emotion labels\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing 5-class labels and one-hot encoded versions\n",
    "    \"\"\"\n",
    "    # Define new emotion map\n",
    "    new_emotion_map = {\n",
    "        0: 'Positive',\n",
    "        1: 'Negative-High Arousal',\n",
    "        2: 'Negative-Low Arousal',\n",
    "        3: 'Surprise',\n",
    "        4: 'Neutral'\n",
    "    }\n",
    "    \n",
    "    # Apply mapping to training and validation sets\n",
    "    y_train_5class = np.array([map_emotions_to_five_classes(label) for label in y_train])\n",
    "    y_val_5class = np.array([map_emotions_to_five_classes(label) for label in y_val])\n",
    "    \n",
    "    # Process test set if provided\n",
    "    if y_test is not None:\n",
    "        y_test_5class = np.array([map_emotions_to_five_classes(label) for label in y_test])\n",
    "    else:\n",
    "        y_test_5class = None\n",
    "    \n",
    "    # Create one-hot encoded versions for CNN models\n",
    "    y_train_5class_onehot = to_categorical(y_train_5class, 5)\n",
    "    y_val_5class_onehot = to_categorical(y_val_5class, 5)\n",
    "    \n",
    "    if y_test_5class is not None:\n",
    "        y_test_5class_onehot = to_categorical(y_test_5class, 5)\n",
    "    else:\n",
    "        y_test_5class_onehot = None\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"5-class mapping successfully created.\")\n",
    "    print(f\"Training labels shape: {y_train_5class.shape}\")\n",
    "    print(f\"Validation labels shape: {y_val_5class.shape}\")\n",
    "    \n",
    "    # Return dictionary with all versions\n",
    "    return {\n",
    "        'y_train_5class': y_train_5class,\n",
    "        'y_val_5class': y_val_5class,\n",
    "        'y_test_5class': y_test_5class,\n",
    "        'y_train_5class_onehot': y_train_5class_onehot,\n",
    "        'y_val_5class_onehot': y_val_5class_onehot,\n",
    "        'y_test_5class_onehot': y_test_5class_onehot,\n",
    "        'new_emotion_map': new_emotion_map\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Analysis of Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.3 Analyze 5-Class Distribution\n",
    "\n",
    "def analyze_class_distribution(y_train, y_val, y_test=None, emotion_map=None):\n",
    "    \"\"\"\n",
    "    Analyze class distribution in the dataset and compute class weights.\n",
    "    \n",
    "    Args:\n",
    "        y_train, y_val, y_test: Labels for each split\n",
    "        emotion_map: Mapping from label indices to emotion names\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of class balance information\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    \n",
    "    # Default emotion map if none provided\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Count class occurrences\n",
    "    train_counts = Counter(y_train)\n",
    "    val_counts = Counter(y_val)\n",
    "    test_counts = Counter(y_test) if y_test is not None else None\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"\\nClass distribution:\")\n",
    "    \n",
    "    # Find the total number of classes\n",
    "    num_classes = len(emotion_map)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        if i in train_counts:\n",
    "            emotion = emotion_map[i]\n",
    "            train_count = train_counts[i]\n",
    "            train_pct = train_count / len(y_train) * 100\n",
    "            val_count = val_counts[i]\n",
    "            val_pct = val_count / len(y_val) * 100\n",
    "            \n",
    "            output = f\"{emotion}: Train={train_count} ({train_pct:.1f}%), Val={val_count} ({val_pct:.1f}%)\"\n",
    "            \n",
    "            if test_counts is not None:\n",
    "                test_count = test_counts[i]\n",
    "                test_pct = test_count / len(y_test) * 100\n",
    "                output += f\", Test={test_count} ({test_pct:.1f}%)\"\n",
    "                \n",
    "            print(output)\n",
    "    \n",
    "    # Compute class weights for loss function\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    \n",
    "    class_weights_dict = {i: class_weights[idx] for idx, i in enumerate(np.unique(y_train))}\n",
    "    \n",
    "    # Print class weights\n",
    "    print(\"\\nClass weights for balanced training:\")\n",
    "    for class_id, weight in class_weights_dict.items():\n",
    "        print(f\"  Class {class_id} ({emotion_map[class_id]}): {weight:.2f}\")\n",
    "    \n",
    "    # Compute imbalance metrics\n",
    "    majority_class = max(train_counts.items(), key=lambda x: x[1])[0]\n",
    "    minority_class = min(train_counts.items(), key=lambda x: x[1])[0]\n",
    "    imbalance_ratio = train_counts[majority_class] / train_counts[minority_class]\n",
    "    \n",
    "    print(f\"\\nImbalance ratio (majority:minority): {imbalance_ratio:.2f}\")\n",
    "    print(f\"Majority class: {emotion_map[majority_class]} ({train_counts[majority_class]} samples)\")\n",
    "    print(f\"Minority class: {emotion_map[minority_class]} ({train_counts[minority_class]} samples)\")\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    emotions = [emotion_map[i] for i in range(num_classes) if i in train_counts]\n",
    "    train_vals = [train_counts[i] for i in range(num_classes) if i in train_counts]\n",
    "    val_vals = [val_counts[i] for i in range(num_classes) if i in train_counts]\n",
    "    \n",
    "    # Create bar plot\n",
    "    x = np.arange(len(emotions))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, train_vals, width, label='Train')\n",
    "    plt.bar(x, val_vals, width, label='Validation')\n",
    "    \n",
    "    if test_counts is not None:\n",
    "        test_vals = [test_counts[i] for i in range(num_classes) if i in train_counts]\n",
    "        plt.bar(x + width, test_vals, width, label='Test')\n",
    "    \n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Class Distribution Across Data Splits')\n",
    "    plt.xticks(x, emotions, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'train_counts': train_counts,\n",
    "        'val_counts': val_counts,\n",
    "        'test_counts': test_counts,\n",
    "        'class_weights': class_weights_dict,\n",
    "        'imbalance_ratio': imbalance_ratio,\n",
    "        'majority_class': majority_class,\n",
    "        'minority_class': minority_class\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 3.4 Data Augmentation for 5-Class Model\n",
    "\n",
    "def create_augmentation_generator(emotion_specific=True):\n",
    "    \"\"\"\n",
    "    Create data augmentation generator optimized for the 5-class emotion model.\n",
    "    \n",
    "    Args:\n",
    "        emotion_specific: Whether to use emotion-specific augmentation parameters\n",
    "        \n",
    "    Returns:\n",
    "        Configured ImageDataGenerator and emotion-specific generators\n",
    "    \"\"\"\n",
    "    # Base augmentation parameters\n",
    "    base_params = {\n",
    "        'rotation_range': 15,\n",
    "        'width_shift_range': 0.1,\n",
    "        'height_shift_range': 0.1,\n",
    "        'zoom_range': 0.1,\n",
    "        'horizontal_flip': True,\n",
    "        'brightness_range': [0.8, 1.2],\n",
    "        'fill_mode': 'nearest'\n",
    "        # No rescale parameter - we'll normalize images separately\n",
    "    }\n",
    "    \n",
    "    # Create generator with base parameters\n",
    "    train_datagen = ImageDataGenerator(**base_params)\n",
    "    \n",
    "    # For emotion-specific augmentation, we now use 5-class categories\n",
    "    emotion_generators = {}\n",
    "    if emotion_specific:\n",
    "        # 5-class emotion-specific augmentation parameters\n",
    "        emotion_params = {\n",
    "            # Positive (Happy)\n",
    "            0: {**base_params, 'rotation_range': 20, 'zoom_range': 0.15},\n",
    "            \n",
    "            # Negative-High Arousal (Angry, Disgust)\n",
    "            1: {**base_params, 'rotation_range': 10, 'brightness_range': [0.7, 1.1]},\n",
    "            \n",
    "            # Negative-Low Arousal (Fear, Sad)\n",
    "            2: {**base_params, 'zoom_range': 0.05, 'brightness_range': [0.85, 1.1]},\n",
    "            \n",
    "            # Surprise\n",
    "            3: {**base_params, 'height_shift_range': 0.05, 'zoom_range': 0.05},\n",
    "            \n",
    "            # Neutral\n",
    "            4: {**base_params, 'rotation_range': 10, 'zoom_range': 0.05}\n",
    "        }\n",
    "        \n",
    "        # Create specialized generators\n",
    "        for emotion_id, params in emotion_params.items():\n",
    "            emotion_generators[emotion_id] = ImageDataGenerator(**params)\n",
    "    \n",
    "    # Create generator for validation (no augmentation)\n",
    "    val_datagen = ImageDataGenerator()\n",
    "    \n",
    "    print(\"Created augmentation generators for 5-class model:\")\n",
    "    print(\"- Base generator for general augmentation\")\n",
    "    if emotion_specific:\n",
    "        print(\"- 5 emotion-specific generators with parameters tailored to each emotion category\")\n",
    "    \n",
    "    return train_datagen, val_datagen, emotion_generators if emotion_specific else None\n",
    "\n",
    "def generate_augmented_data_func(X_train, y_train_5class, emotion_generators, \n",
    "                            samples_per_class=1000, random_state=42):\n",
    "    \"\"\"\n",
    "    Generate augmented samples for each emotion class and combine with original data.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Original training images\n",
    "        y_train_5class: 5-class emotion labels\n",
    "        emotion_generators: Dictionary of emotion-specific generators\n",
    "        samples_per_class: Target number of samples per class after augmentation\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Combined original and augmented data with labels\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Copy original data\n",
    "    X_augmented = X_train.copy()\n",
    "    y_augmented = y_train_5class.copy()\n",
    "    \n",
    "    print(\"Generating augmented samples:\")\n",
    "    \n",
    "    # Get emotion map\n",
    "    emotion_map = {\n",
    "        0: 'Positive',\n",
    "        1: 'Negative-High Arousal',\n",
    "        2: 'Negative-Low Arousal',\n",
    "        3: 'Surprise',\n",
    "        4: 'Neutral'\n",
    "    }\n",
    "    \n",
    "    # For each emotion class\n",
    "    for emotion in range(5):\n",
    "        # Count original samples for this class\n",
    "        original_indices = np.where(y_train_5class == emotion)[0]\n",
    "        original_count = len(original_indices)\n",
    "        \n",
    "        # Calculate how many samples to generate\n",
    "        target_count = samples_per_class\n",
    "        generate_count = max(0, target_count - original_count)\n",
    "        \n",
    "        print(f\"  Class {emotion} ({emotion_map[emotion]}): {original_count} original samples\")\n",
    "        \n",
    "        if generate_count <= 0:\n",
    "            print(f\"    Already have enough samples, no augmentation needed\")\n",
    "            continue\n",
    "            \n",
    "        print(f\" Generating {generate_count} augmented samples\")\n",
    "        \n",
    "        # Select indices to augment (with replacement if needed)\n",
    "        if original_count < generate_count:\n",
    "            augment_indices = np.random.choice(original_indices, generate_count, replace=True)\n",
    "        else:\n",
    "            augment_indices = np.random.choice(original_indices, generate_count, replace=False)\n",
    "        \n",
    "        # Get appropriate generator\n",
    "        if emotion in emotion_generators:\n",
    "            generator = emotion_generators[emotion]\n",
    "        else:\n",
    "            generator = train_datagen\n",
    "            \n",
    "        # Generate augmented samples\n",
    "        augmented_batch = []\n",
    "        for i, idx in enumerate(augment_indices):\n",
    "            # Prepare image for generator - normalize first\n",
    "            img_float = X_train[idx].astype('float32') / 255.0  # Normalize to [0,1]\n",
    "            img_reshaped = img_float.reshape(1, 48, 48, 1)\n",
    "            \n",
    "            # Generate augmented image\n",
    "            aug_img = next(generator.flow(img_reshaped, batch_size=1))[0]\n",
    "            \n",
    "            # Convert back to original scale if needed\n",
    "            if X_train.max() > 1.0:\n",
    "                aug_img = (aug_img * 255.0).astype(X_train.dtype)\n",
    "            \n",
    "            # Add to batch\n",
    "            augmented_batch.append(aug_img.reshape(48, 48))\n",
    "            \n",
    "            # Print progress\n",
    "            if (i+1) % 500 == 0:\n",
    "                print(f\"      Generated {i+1}/{generate_count} samples\")\n",
    "        \n",
    "        # Add batch to augmented dataset\n",
    "        X_augmented = np.vstack([X_augmented, np.array(augmented_batch)])\n",
    "        y_augmented = np.append(y_augmented, np.array([emotion] * len(augmented_batch)))\n",
    "    \n",
    "    print(\"\\nAugmented dataset statistics:\")\n",
    "    print(f\"  Original dataset size: {len(X_train)} samples\")\n",
    "    print(f\"  Augmented dataset size: {len(X_augmented)} samples\")\n",
    "    \n",
    "    for emotion in range(5):\n",
    "        original_count = np.sum(y_train_5class == emotion)\n",
    "        augmented_count = np.sum(y_augmented == emotion)\n",
    "        print(f\"  Class {emotion} ({emotion_map[emotion]}): {original_count} → {augmented_count} samples\")\n",
    "    \n",
    "    return X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                        use_5class=True, balance_method=None, \n",
    "                        generate_augmented_data=True, samples_per_class=1000,\n",
    "                        extract_features=True, select_n_features=75,\n",
    "                        save_results=False, save_path='preprocessed_data'):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for the facial emotion recognition model.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_val, X_test: Image data\n",
    "        y_train, y_val, y_test: Original emotion labels\n",
    "        use_5class: Whether to use 5-class emotion mapping\n",
    "        balance_method: Method for class balancing (None, 'augmentation')\n",
    "        generate_augmented_data: Whether to generate augmented data\n",
    "        samples_per_class: Target number of samples per class\n",
    "        extract_features: Whether to extract features\n",
    "        select_n_features: Number of features to select\n",
    "        save_results: Whether to save results\n",
    "        save_path: Path to save results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of preprocessed data\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Check for and filter out black images\n",
    "    print(\"Step 1: Checking for black images...\")\n",
    "    \n",
    "    def filter_black_images(X, y, threshold=0.1):\n",
    "        valid_indices = []\n",
    "        removed_indices = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if np.max(X[i]) > threshold:\n",
    "                valid_indices.append(i)\n",
    "            else:\n",
    "                removed_indices.append(i)\n",
    "        \n",
    "        X_filtered = X[valid_indices]\n",
    "        y_filtered = y[valid_indices]\n",
    "        \n",
    "        print(f\"  Removed {len(removed_indices)} black images out of {len(X)} total images.\")\n",
    "        \n",
    "        return X_filtered, y_filtered\n",
    "    \n",
    "    X_train, y_train = filter_black_images(X_train, y_train)\n",
    "    X_val, y_val = filter_black_images(X_val, y_val)\n",
    "    X_test, y_test = filter_black_images(X_test, y_test)\n",
    "    \n",
    "    # Step 2: Create 5-class mapping if requested\n",
    "    if use_5class:\n",
    "        print(\"\\nStep 2: Creating 5-class emotion mapping...\")\n",
    "        five_class_data = create_five_class_mapping(y_train, y_val, y_test)\n",
    "        y_train_5class = five_class_data['y_train_5class']\n",
    "        y_val_5class = five_class_data['y_val_5class']\n",
    "        y_test_5class = five_class_data['y_test_5class']\n",
    "        y_train_5class_onehot = five_class_data['y_train_5class_onehot']\n",
    "        y_val_5class_onehot = five_class_data['y_val_5class_onehot']\n",
    "        y_test_5class_onehot = five_class_data['y_test_5class_onehot']\n",
    "        new_emotion_map = five_class_data['new_emotion_map']\n",
    "        \n",
    "        # Analyze class distribution\n",
    "        class_info = analyze_class_distribution(y_train_5class, y_val_5class, y_test_5class, new_emotion_map)\n",
    "        class_weights = class_info['class_weights']\n",
    "    else:\n",
    "        print(\"\\nStep 2: Keeping original 7-class emotions...\")\n",
    "        y_train_5class = y_train\n",
    "        y_val_5class = y_val\n",
    "        y_test_5class = y_test\n",
    "        y_train_5class_onehot = to_categorical(y_train, 7)\n",
    "        y_val_5class_onehot = to_categorical(y_val, 7)\n",
    "        y_test_5class_onehot = to_categorical(y_test, 7)\n",
    "        new_emotion_map = {\n",
    "            0: 'Angry', 1: 'Disgust', 2: 'Fear', \n",
    "            3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'\n",
    "        }\n",
    "        \n",
    "        # Analyze class distribution\n",
    "        class_info = analyze_class_distribution(y_train, y_val, y_test, new_emotion_map)\n",
    "        class_weights = class_info['class_weights']\n",
    "    \n",
    "    # Step 3: Normalize images (only once!)\n",
    "    print(\"\\nStep 3: Normalizing images...\")\n",
    "    \n",
    "    # Check if already normalized\n",
    "    if X_train.max() <= 1.0 and X_train.min() >= 0.0:\n",
    "        print(\"  Images are already normalized to [0,1] range\")\n",
    "        X_train_norm = X_train\n",
    "        X_val_norm = X_val\n",
    "        X_test_norm = X_test\n",
    "    else:\n",
    "        print(\"  Normalizing images to [0,1] range\")\n",
    "        print(f\"  Before normalization - X_train min: {X_train.min()}, max: {X_train.max()}, mean: {X_train.mean():.4f}\")\n",
    "        \n",
    "        X_train_norm = X_train.astype('float32') / 255.0\n",
    "        X_val_norm = X_val.astype('float32') / 255.0\n",
    "        X_test_norm = X_test.astype('float32') / 255.0\n",
    "        \n",
    "        print(f\"  After normalization - X_train min: {X_train_norm.min()}, max: {X_train_norm.max()}, mean: {X_train_norm.mean():.4f}\")\n",
    "    \n",
    "    # Add channel dimension for CNN models\n",
    "    X_train_cnn = X_train_norm.reshape(X_train_norm.shape[0], 48, 48, 1)\n",
    "    X_val_cnn = X_val_norm.reshape(X_val_norm.shape[0], 48, 48, 1)\n",
    "    X_test_cnn = X_test_norm.reshape(X_test_norm.shape[0], 48, 48, 1)\n",
    "    \n",
    "    # Step 4: Generate augmented data if requested\n",
    "    if generate_augmented_data and balance_method == 'augmentation':\n",
    "        print(\"\\nStep 4: Generating augmented data...\")\n",
    "        \n",
    "        # Create augmentation generators\n",
    "        train_datagen, val_datagen, emotion_generators = create_augmentation_generator(emotion_specific=True)\n",
    "        \n",
    "        # Generate augmented data\n",
    "        print(f\"  Generating augmented data with target {samples_per_class} samples per class...\")\n",
    "        X_train_aug, y_train_aug = generate_augmented_data_func(\n",
    "            X_train, y_train_5class, emotion_generators, \n",
    "            samples_per_class=samples_per_class\n",
    "        )\n",
    "        \n",
    "        # Create one-hot encoded labels for augmented data\n",
    "        num_classes = 5 if use_5class else 7\n",
    "        y_train_aug_onehot = to_categorical(y_train_aug, num_classes)\n",
    "        \n",
    "        # Reshape for CNN\n",
    "        X_train_aug_cnn = X_train_aug.astype('float32') / 255.0\n",
    "        X_train_aug_cnn = X_train_aug_cnn.reshape(X_train_aug_cnn.shape[0], 48, 48, 1)\n",
    "    else:\n",
    "        print(\"\\nStep 4: Skipping data augmentation\")\n",
    "        X_train_aug = X_train\n",
    "        y_train_aug = y_train_5class\n",
    "        y_train_aug_onehot = y_train_5class_onehot\n",
    "        X_train_aug_cnn = X_train_cnn\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        val_datagen = ImageDataGenerator()\n",
    "    \n",
    "    # Step 5: Extract features for traditional ML models if requested\n",
    "    if extract_features:\n",
    "        print(\"\\nStep 5: Extracting features for traditional ML models...\")\n",
    "        \n",
    "        # Extract features from original data\n",
    "        X_train_features, feature_groups = extract_facial_features(X_train)\n",
    "        X_val_features, _ = extract_facial_features(X_val)\n",
    "        X_test_features, _ = extract_facial_features(X_test)\n",
    "        \n",
    "        print(f\"  Extracted {X_train_features.shape[1]} features from each image\")\n",
    "        \n",
    "        # Extract features from augmented data if it was generated\n",
    "        if generate_augmented_data and balance_method == 'augmentation':\n",
    "            print(\"  Extracting features from augmented data...\")\n",
    "            X_train_aug_features, _ = extract_facial_features(X_train_aug)\n",
    "        else:\n",
    "            X_train_aug_features = X_train_features\n",
    "        \n",
    "        # Standardize features\n",
    "        print(\"  Standardizing features...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_features)\n",
    "        X_val_scaled = scaler.transform(X_val_features)\n",
    "        X_test_scaled = scaler.transform(X_test_features)\n",
    "        \n",
    "        if generate_augmented_data and balance_method == 'augmentation':\n",
    "            X_train_aug_scaled = scaler.transform(X_train_aug_features)\n",
    "        else:\n",
    "            X_train_aug_scaled = X_train_scaled\n",
    "        \n",
    "        # Step 6: Select most informative features if requested\n",
    "        if select_n_features > 0:\n",
    "            print(f\"\\nStep 6: Selecting {select_n_features} most informative features...\")\n",
    "            \n",
    "            # Feature selection using mutual information\n",
    "            selector = SelectKBest(mutual_info_classif, k=select_n_features)\n",
    "            X_train_selected = selector.fit_transform(X_train_scaled, y_train_5class)\n",
    "            X_val_selected = selector.transform(X_val_scaled)\n",
    "            X_test_selected = selector.transform(X_test_scaled)\n",
    "            X_train_aug_selected = selector.transform(X_train_aug_scaled)\n",
    "            \n",
    "            # Get feature importance\n",
    "            feature_scores = selector.scores_\n",
    "            feature_indices = selector.get_support(indices=True)\n",
    "            \n",
    "            # Get feature names if available\n",
    "            if hasattr(X_train_features, 'columns'):\n",
    "                feature_names = X_train_features.columns\n",
    "                selected_features = [feature_names[i] for i in feature_indices]\n",
    "            else:\n",
    "                selected_features = [f\"feature_{i}\" for i in feature_indices]\n",
    "            \n",
    "            # Print top features\n",
    "            print(\"  Top 10 selected features:\")\n",
    "            sorted_indices = np.argsort(feature_scores[feature_indices])[::-1]\n",
    "            for i in range(min(10, len(selected_features))):\n",
    "                idx = sorted_indices[i]\n",
    "                print(f\"    {i+1}. {selected_features[idx]}: {feature_scores[feature_indices[idx]]:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nStep 6: Skipping feature selection\")\n",
    "            X_train_selected = X_train_scaled\n",
    "            X_val_selected = X_val_scaled\n",
    "            X_test_selected = X_test_scaled\n",
    "            X_train_aug_selected = X_train_aug_scaled\n",
    "            selector = None\n",
    "            selected_features = None\n",
    "    else:\n",
    "        print(\"\\nSteps 5-6: Skipping feature extraction and selection\")\n",
    "        X_train_features = None\n",
    "        X_val_features = None\n",
    "        X_test_features = None\n",
    "        X_train_aug_features = None\n",
    "        X_train_scaled = None\n",
    "        X_val_scaled = None\n",
    "        X_test_scaled = None\n",
    "        X_train_aug_scaled = None\n",
    "        X_train_selected = None\n",
    "        X_val_selected = None\n",
    "        X_test_selected = None\n",
    "        X_train_aug_selected = None\n",
    "        feature_groups = None\n",
    "        scaler = None\n",
    "        selector = None\n",
    "        selected_features = None\n",
    "    \n",
    "    # Step 7: Save results if requested\n",
    "    if save_results:\n",
    "        print(\"\\nStep 7: Saving preprocessed data...\")\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Save numpy arrays\n",
    "        arrays_to_save = {\n",
    "            'X_train.npy': X_train,\n",
    "            'X_val.npy': X_val,\n",
    "            'X_test.npy': X_test,\n",
    "            'y_train.npy': y_train,\n",
    "            'y_val.npy': y_val,\n",
    "            'y_test.npy': y_test,\n",
    "            'y_train_5class.npy': y_train_5class,\n",
    "            'y_val_5class.npy': y_val_5class,\n",
    "            'y_test_5class.npy': y_test_5class,\n",
    "            'X_train_norm.npy': X_train_norm,\n",
    "            'X_val_norm.npy': X_val_norm,\n",
    "            'X_test_norm.npy': X_test_norm,\n",
    "            'X_train_cnn.npy': X_train_cnn,\n",
    "            'X_val_cnn.npy': X_val_cnn,\n",
    "            'X_test_cnn.npy': X_test_cnn\n",
    "        }\n",
    "        \n",
    "        # Add augmented data if available\n",
    "        if generate_augmented_data and balance_method == 'augmentation':\n",
    "            arrays_to_save.update({\n",
    "                'X_train_aug.npy': X_train_aug,\n",
    "                'y_train_aug.npy': y_train_aug,\n",
    "                'X_train_aug_cnn.npy': X_train_aug_cnn\n",
    "            })\n",
    "        \n",
    "        # Add selected features if available\n",
    "        if extract_features and X_train_selected is not None:\n",
    "            arrays_to_save.update({\n",
    "                'X_train_selected.npy': X_train_selected,\n",
    "                'X_val_selected.npy': X_val_selected,\n",
    "                'X_test_selected.npy': X_test_selected\n",
    "            })\n",
    "            \n",
    "            if generate_augmented_data and balance_method == 'augmentation':\n",
    "                arrays_to_save['X_train_aug_selected.npy'] = X_train_aug_selected\n",
    "        \n",
    "        # Save arrays\n",
    "        saved_count = 0\n",
    "        for filename, array in arrays_to_save.items():\n",
    "            if array is not None:\n",
    "                np.save(os.path.join(save_path, filename), array)\n",
    "                saved_count += 1\n",
    "        \n",
    "        # Save other objects\n",
    "        import pickle\n",
    "        \n",
    "        other_data = {\n",
    "            'class_weights': class_weights,\n",
    "            'new_emotion_map': new_emotion_map,\n",
    "            'class_info': class_info,\n",
    "            'feature_groups': feature_groups,\n",
    "            'scaler': scaler,\n",
    "            'selector': selector,\n",
    "            'selected_features': selected_features\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(save_path, 'metadata.pkl'), 'wb') as f:\n",
    "            pickle.dump(other_data, f)\n",
    "        \n",
    "        print(f\"  Saved {saved_count} arrays and metadata to {save_path}\")\n",
    "    else:\n",
    "        print(\"\\nStep 7: Skipping saving results\")\n",
    "    \n",
    "    # Create results dictionary\n",
    "    results = {\n",
    "        # Original data\n",
    "        'X_train': X_train,\n",
    "        'X_val': X_val,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_val': y_val,\n",
    "        'y_test': y_test,\n",
    "        \n",
    "        # 5-class data\n",
    "        'y_train_5class': y_train_5class,\n",
    "        'y_val_5class': y_val_5class,\n",
    "        'y_test_5class': y_test_5class,\n",
    "        'y_train_5class_onehot': y_train_5class_onehot,\n",
    "        'y_val_5class_onehot': y_val_5class_onehot,\n",
    "        'y_test_5class_onehot': y_test_5class_onehot,\n",
    "        \n",
    "        # Normalized data\n",
    "        'X_train_norm': X_train_norm,\n",
    "        'X_val_norm': X_val_norm,\n",
    "        'X_test_norm': X_test_norm,\n",
    "        \n",
    "        # CNN data\n",
    "        'X_train_cnn': X_train_cnn,\n",
    "        'X_val_cnn': X_val_cnn,\n",
    "        'X_test_cnn': X_test_cnn,\n",
    "        \n",
    "        # Augmented data\n",
    "        'X_train_aug': X_train_aug,\n",
    "        'y_train_aug': y_train_aug,\n",
    "        'y_train_aug_onehot': y_train_aug_onehot,\n",
    "        'X_train_aug_cnn': X_train_aug_cnn,\n",
    "        \n",
    "        # Feature data\n",
    "        'X_train_features': X_train_features,\n",
    "        'X_val_features': X_val_features,\n",
    "        'X_test_features': X_test_features,\n",
    "        'X_train_aug_features': X_train_aug_features,\n",
    "        \n",
    "        # Scaled feature data\n",
    "        'X_train_scaled': X_train_scaled,\n",
    "        'X_val_scaled': X_val_scaled,\n",
    "        'X_test_scaled': X_test_scaled,\n",
    "        'X_train_aug_scaled': X_train_aug_scaled,\n",
    "        \n",
    "        # Selected feature data\n",
    "        'X_train_selected': X_train_selected,\n",
    "        'X_val_selected': X_val_selected, \n",
    "        'X_test_selected': X_test_selected,\n",
    "        'X_train_aug_selected': X_train_aug_selected,\n",
    "        \n",
    "        # Metadata\n",
    "        'class_weights': class_weights,\n",
    "        'new_emotion_map': new_emotion_map,\n",
    "        'class_info': class_info,\n",
    "        'feature_groups': feature_groups,\n",
    "        'scaler': scaler,\n",
    "        'selector': selector,\n",
    "        'selected_features': selected_features,\n",
    "        \n",
    "        # Generators\n",
    "        'train_datagen': train_datagen,\n",
    "        'val_datagen': val_datagen\n",
    "    }\n",
    "    \n",
    "    # Total execution time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nPreprocessing completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = preprocess_pipeline(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        use_5class=True,\n",
    "        balance_method='augmentation',  # This is crucial for class balancing\n",
    "        generate_augmented_data=True,   # Enable data augmentation\n",
    "        samples_per_class=8000,         # Target 8000 samples per class\n",
    "        extract_features=True,\n",
    "        select_n_features=75,\n",
    "        save_results=False              # Set to True if you want to save the results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to see if preprocessing was successful\n",
    "if 'processed_data' in globals() and processed_data is not None:\n",
    "    print(\"Preprocessing successful!\")\n",
    "    print(f\"Shapes of key processed datasets:\")\n",
    "    \n",
    "    # Check original data\n",
    "    if 'X_train' in processed_data:\n",
    "        print(f\"  X_train: {processed_data['X_train'].shape}\")\n",
    "    \n",
    "    # Check augmented data\n",
    "    if 'X_train_aug' in processed_data:\n",
    "        print(f\"  X_train_aug: {processed_data['X_train_aug'].shape}\")\n",
    "        print(f\"  Original vs. Augmented size: {len(processed_data['X_train'])} → {len(processed_data['X_train_aug'])}\")\n",
    "    \n",
    "    # Check class distribution in augmented data\n",
    "    if 'y_train_aug' in processed_data:\n",
    "        from collections import Counter\n",
    "        counts = Counter(processed_data['y_train_aug'])\n",
    "        print(\"\\nClass distribution in augmented data:\")\n",
    "        for cls, count in sorted(counts.items()):\n",
    "            print(f\"  Class {cls}: {count} samples\")\n",
    "else:\n",
    "    print(\"Preprocessing did not complete successfully or 'processed_data' is not defined.\")\n",
    "    print(\"You may need to re-run the preprocessing pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Models and Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1 Create and Evaluate 5-Class Traditional ML Models\n",
    "\n",
    "def train_evaluate_traditional_models(X_train, y_train, X_val, y_val, class_weights=None, model_names=None):\n",
    "    \"\"\"\n",
    "    Train and evaluate traditional ML models for 5-class emotion classification.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training labels\n",
    "        X_val: Validation features\n",
    "        y_val: Validation labels\n",
    "        class_weights: Class weights to handle class imbalance\n",
    "        model_names: List of model names to train (default: all)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of trained models and performance metrics\n",
    "    \"\"\"\n",
    "    # Define models to train\n",
    "    all_models = {\n",
    "        'RandomForest': RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=20,\n",
    "            min_samples_split=5,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'GradientBoosting': GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'SVM': SVC(\n",
    "            kernel='rbf',\n",
    "            C=10,\n",
    "            gamma='scale',\n",
    "            class_weight='balanced',\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'KNN': KNeighborsClassifier(\n",
    "            n_neighbors=7,\n",
    "            weights='distance',\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'LogisticRegression': LogisticRegression(\n",
    "            multi_class='multinomial',\n",
    "            solver='lbfgs',\n",
    "            max_iter=1000,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Filter models if specified\n",
    "    if model_names is not None:\n",
    "        models = {name: all_models[name] for name in model_names if name in all_models}\n",
    "    else:\n",
    "        models = all_models\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        report = classification_report(y_val, y_val_pred, output_dict=True)\n",
    "        conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "        \n",
    "        # Calculate training time\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'report': report,\n",
    "            'conf_matrix': conf_matrix,\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Training time: {training_time:.2f} seconds\")\n",
    "        print(\"  Performance by class:\")\n",
    "        \n",
    "        # Print class-wise metrics\n",
    "        for i in range(len(report) - 3):  # Skip 'accuracy', 'macro avg', 'weighted avg'\n",
    "            class_precision = report[str(i)]['precision']\n",
    "            class_recall = report[str(i)]['recall']\n",
    "            class_f1 = report[str(i)]['f1-score']\n",
    "            class_support = report[str(i)]['support']\n",
    "            \n",
    "            print(f\"    Class {i}: Precision={class_precision:.4f}, Recall={class_recall:.4f}, F1={class_f1:.4f}, Support={class_support}\")\n",
    "    \n",
    "    # Find best model based on accuracy\n",
    "    best_model = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "    print(f\"\\nBest model: {best_model[0]} with accuracy {best_model[1]['accuracy']:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_performance(model_results, emotion_map=None):\n",
    "    \"\"\"\n",
    "    Visualize the performance of trained models.\n",
    "    \n",
    "    Args:\n",
    "        model_results: Dictionary of model results\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Extract model names and accuracies\n",
    "    model_names = list(model_results.keys())\n",
    "    accuracies = [model_results[name]['accuracy'] for name in model_names]\n",
    "    training_times = [model_results[name]['training_time'] for name in model_names]\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    sorted_indices = np.argsort(accuracies)[::-1]\n",
    "    sorted_names = [model_names[i] for i in sorted_indices]\n",
    "    sorted_accuracies = [accuracies[i] for i in sorted_indices]\n",
    "    sorted_times = [training_times[i] for i in sorted_indices]\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(sorted_names, sorted_accuracies)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(sorted_names, sorted_times)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Training Time (s)')\n",
    "    plt.title('Model Training Time Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot confusion matrix for the best model\n",
    "    best_model = sorted_names[0]\n",
    "    conf_matrix = model_results[best_model]['conf_matrix']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[emotion_map[i] for i in range(len(emotion_map))],\n",
    "                yticklabels=[emotion_map[i] for i in range(len(emotion_map))])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - {best_model}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot class-wise metrics for all models\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    num_classes = len(emotion_map)\n",
    "    \n",
    "    # Create a figure with a subplot for each metric\n",
    "    plt.figure(figsize=(15, 5 * len(metrics)))\n",
    "    \n",
    "    for m, metric in enumerate(metrics):\n",
    "        plt.subplot(len(metrics), 1, m+1)\n",
    "        \n",
    "        # Extract metric for each model and class\n",
    "        metric_data = []\n",
    "        for name in model_names:\n",
    "            report = model_results[name]['report']\n",
    "            class_metrics = [report[str(i)][metric] for i in range(num_classes)]\n",
    "            metric_data.append(class_metrics)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        metric_data = np.array(metric_data)\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(metric_data, annot=True, fmt='.2f', cmap='YlGnBu',\n",
    "                    xticklabels=[emotion_map[i] for i in range(num_classes)],\n",
    "                    yticklabels=model_names)\n",
    "        plt.xlabel('Emotion Class')\n",
    "        plt.ylabel('Model')\n",
    "        plt.title(f'{metric.capitalize()} by Model and Emotion Class')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.2 Create and Train 5-Class CNN Models\n",
    "\n",
    "def create_emotion_cnn(input_shape=(48, 48, 1), num_classes=5):\n",
    "    \"\"\"\n",
    "    Create a CNN model for emotion classification.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input images\n",
    "        num_classes: Number of emotion classes\n",
    "        \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First convolutional block\n",
    "        Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"CNN Model Summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_cnn(input_shape=(48, 48, 1), num_classes=5):\n",
    "    \"\"\"\n",
    "    Create a CNN with attention mechanism for emotion classification.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input images\n",
    "        num_classes: Number of emotion classes\n",
    "        \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.layers import multiply, Reshape, Permute, GlobalAveragePooling2D, Activation\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Third convolutional block with attention\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    feature_maps = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(feature_maps)\n",
    "    \n",
    "    # Spatial attention mechanism\n",
    "    attention = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(x)\n",
    "    x = multiply([feature_maps, attention])\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"Attention CNN Model Summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_model(model, X_train, y_train, X_val, y_val, \n",
    "                    batch_size=64, epochs=50, class_weights=None, \n",
    "                    model_name=\"emotion_cnn\", save_best=True):\n",
    "    \"\"\"\n",
    "    Train a CNN model with early stopping and learning rate reduction.\n",
    "    \n",
    "    Args:\n",
    "        model: Compiled Keras model\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels\n",
    "        batch_size: Batch size for training\n",
    "        epochs: Maximum number of epochs\n",
    "        class_weights: Class weights for imbalanced data\n",
    "        model_name: Name for saving the model\n",
    "        save_best: Whether to save the best model during training\n",
    "        \n",
    "    Returns:\n",
    "        Trained model and training history\n",
    "    \"\"\"\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Add model checkpoint callback if save_best is True\n",
    "    if save_best:\n",
    "        callbacks.append(\n",
    "            ModelCheckpoint(\n",
    "                f\"{model_name}_best.keras\",\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def visualize_training_history(history, title=\"Model Training History\"):\n",
    "    \"\"\"\n",
    "    Visualize the training history of a CNN model.\n",
    "    \n",
    "    Args:\n",
    "        history: Training history from model.fit()\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_cnn_model(model, X_val, y_val, emotion_map=None):\n",
    "    \"\"\"\n",
    "    Evaluate a trained CNN model on test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        X_val: val features\n",
    "        y_val: val labels (one-hot encoded)\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nPerformance by class:\")\n",
    "    \n",
    "    # Print class-wise metrics\n",
    "    for i in range(len(emotion_map)):\n",
    "        if str(i) in report:\n",
    "            class_precision = report[str(i)]['precision']\n",
    "            class_recall = report[str(i)]['recall']\n",
    "            class_f1 = report[str(i)]['f1-score']\n",
    "            class_support = report[str(i)]['support']\n",
    "            \n",
    "            print(f\"  Class {i} ({emotion_map[i]}): Precision={class_precision:.4f}, Recall={class_recall:.4f}, F1={class_f1:.4f}, Support={class_support}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[emotion_map[i] for i in range(len(emotion_map))],\n",
    "                yticklabels=[emotion_map[i] for i in range(len(emotion_map))])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return evaluation results\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'conf_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "def visualize_model_predictions(model, X_val, y_val, emotion_map=None, num_samples=6):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on sample test images.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        X_val: val features\n",
    "        y_val: val labels (one-hot encoded)\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "        num_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Find some correctly and incorrectly classified examples\n",
    "    correct_indices = np.where(y_pred == y_true)[0]\n",
    "    incorrect_indices = np.where(y_pred != y_true)[0]\n",
    "    \n",
    "    # Determine how many of each to show\n",
    "    n_correct = min(num_samples // 2 + num_samples % 2, len(correct_indices))\n",
    "    n_incorrect = min(num_samples // 2, len(incorrect_indices))\n",
    "    \n",
    "    # Sample indices\n",
    "    if len(correct_indices) > 0:\n",
    "        sampled_correct = np.random.choice(correct_indices, n_correct, replace=False)\n",
    "    else:\n",
    "        sampled_correct = []\n",
    "    \n",
    "    if len(incorrect_indices) > 0:\n",
    "        sampled_incorrect = np.random.choice(incorrect_indices, n_incorrect, replace=False)\n",
    "    else:\n",
    "        sampled_incorrect = []\n",
    "    \n",
    "    # Combine samples\n",
    "    sampled_indices = np.concatenate([sampled_correct, sampled_incorrect])\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(15, n_correct + n_incorrect))\n",
    "    \n",
    "    # Plot each sample\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        # Get image and reshape if needed\n",
    "        img = X_val[idx]\n",
    "        if len(img.shape) == 3 and img.shape[-1] == 1:\n",
    "            img = img.reshape(img.shape[0], img.shape[1])\n",
    "        \n",
    "        # Get true and predicted labels\n",
    "        true_label = y_true[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "        pred_prob = y_pred_prob[idx][pred_label]\n",
    "        \n",
    "        # Determine color based on correctness\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        \n",
    "        # Plot image\n",
    "        plt.subplot(len(sampled_indices), 1, i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"True: {emotion_map[true_label]} | Predicted: {emotion_map[pred_label]} ({pred_prob:.2f})\", \n",
    "                    color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compare_models_performance(results_dict, emotion_map=None):\n",
    "    \"\"\"\n",
    "    Compare the performance of multiple trained models.\n",
    "    \n",
    "    Args:\n",
    "        results_dict: Dictionary of model evaluation results\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Extract model names and accuracies\n",
    "    model_names = list(results_dict.keys())\n",
    "    accuracies = [results_dict[name]['accuracy'] for name in model_names]\n",
    "    \n",
    "    # Create bar chart for accuracies\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(model_names, accuracies)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add accuracy values above bars\n",
    "    for i, v in enumerate(accuracies):\n",
    "        plt.text(i, v + 0.01, f\"{v:.4f}\", ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a table for class-wise F1 scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('Class-wise F1 Scores')\n",
    "    \n",
    "    # Extract F1 scores for each model and class\n",
    "    f1_scores = np.zeros((len(model_names), len(emotion_map)))\n",
    "    \n",
    "    for i, name in enumerate(model_names):\n",
    "        report = results_dict[name]['report']\n",
    "        for j in range(len(emotion_map)):\n",
    "            if str(j) in report:\n",
    "                f1_scores[i, j] = report[str(j)]['f1-score']\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(f1_scores, annot=True, fmt='.3f', cmap='YlGnBu',\n",
    "                xticklabels=[emotion_map[i] for i in range(len(emotion_map))],\n",
    "                yticklabels=model_names)\n",
    "    plt.xlabel('Emotion Class')\n",
    "    plt.ylabel('Model')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Traditional ML Models\n",
    "# First, make sure you have the right features for traditional ML models\n",
    "if processed_data is not None and 'X_train_selected' in processed_data:\n",
    "    print(\"Training traditional ML models...\")\n",
    "    ml_results = train_evaluate_traditional_models(\n",
    "        processed_data['X_train_selected'], \n",
    "        processed_data['y_train_5class'],\n",
    "        processed_data['X_val_selected'], \n",
    "        processed_data['y_val_5class'],\n",
    "        class_weights=processed_data['class_weights']\n",
    "    )\n",
    "    \n",
    "    # Visualize model performance\n",
    "    visualize_model_performance(ml_results, processed_data['new_emotion_map'])\n",
    "else:\n",
    "    print(\"Cannot train traditional ML models: processed data not available or missing selected features\")\n",
    "\n",
    "# Train CNN Models\n",
    "if processed_data is not None and 'X_train_aug_cnn' in processed_data:\n",
    "    # 1. Basic CNN model\n",
    "    print(\"\\nTraining basic CNN model...\")\n",
    "    cnn_model = create_emotion_cnn(input_shape=(48, 48, 1), num_classes=5)\n",
    "    \n",
    "    trained_cnn, cnn_history = train_cnn_model(\n",
    "        cnn_model,\n",
    "        processed_data['X_train_aug_cnn'],\n",
    "        processed_data['y_train_aug_onehot'],\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        batch_size=64,\n",
    "        epochs=50,\n",
    "        class_weights=processed_data['class_weights'],\n",
    "        model_name=\"basic_cnn\"\n",
    "    )\n",
    "    \n",
    "    # Visualize training history\n",
    "    visualize_training_history(cnn_history, title=\"Basic CNN Training History\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    cnn_evaluation = evaluate_cnn_model(\n",
    "        trained_cnn,\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        emotion_map=processed_data['new_emotion_map']\n",
    "    )\n",
    "    \n",
    "    # 2. Attention CNN model\n",
    "    print(\"\\nTraining attention CNN model...\")\n",
    "    attention_model = create_attention_cnn(input_shape=(48, 48, 1), num_classes=5)\n",
    "    \n",
    "    trained_attention, attention_history = train_cnn_model(\n",
    "        attention_model,\n",
    "        processed_data['X_train_aug_cnn'],\n",
    "        processed_data['y_train_aug_onehot'],\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        batch_size=64,\n",
    "        epochs=50,\n",
    "        class_weights=processed_data['class_weights'],\n",
    "        model_name=\"attention_cnn\"\n",
    "    )\n",
    "    \n",
    "    # Visualize training history\n",
    "    visualize_training_history(attention_history, title=\"Attention CNN Training History\")\n",
    "    \n",
    "    # Evaluate on val set\n",
    "    attention_evaluation = evaluate_cnn_model(\n",
    "        trained_attention,\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        emotion_map=processed_data['new_emotion_map']\n",
    "    )\n",
    "    \n",
    "    # Compare model performance\n",
    "    model_comparison = {\n",
    "        'Basic CNN': cnn_evaluation,\n",
    "        'Attention CNN': attention_evaluation\n",
    "    }\n",
    "    \n",
    "    compare_models_performance(model_comparison, processed_data['new_emotion_map'])\n",
    "    \n",
    "    # Visualize model predictions\n",
    "    visualize_model_predictions(\n",
    "        trained_attention,\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        emotion_map=processed_data['new_emotion_map'],\n",
    "        num_samples=6\n",
    "    )\n",
    "else:\n",
    "    print(\"Cannot train CNN models: processed data not available or missing augmented CNN data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Current Results\n",
    "\n",
    "Model Performance Comparison:\n",
    "\n",
    "The CNNs (Basic CNN: 66.42%, Attention CNN: 65.47%) significantly outperform the traditional ML models (best was RandomForest at 51.31%)\n",
    "The attention mechanism doesn't seem to provide a substantial improvement over the basic CNN in overall accuracy\n",
    "\n",
    "\n",
    "Class-wise Performance:\n",
    "\n",
    "Both CNN models perform very well on \"Positive\" emotions (~82% F1 score) and \"Surprise\" (~74% F1 score)\n",
    "Both struggle more with \"Negative-High Arousal\" and \"Negative-Low Arousal\" categories\n",
    "There's confusion between similar emotion classes (e.g., between the two negative emotion categories)\n",
    "\n",
    "\n",
    "Training Dynamics:\n",
    "\n",
    "From the training history plots, both models show early convergence with validation accuracy stabilizing around 25 epochs\n",
    "There's a small gap between training and validation accuracy, suggesting the models aren't overfitting significantly\n",
    "Early stopping is working correctly, preventing overfitting\n",
    "\n",
    "\n",
    "Traditional ML Models:\n",
    "\n",
    "RandomForest performed best among traditional models (51.31%)\n",
    "Traditional models show varying strengths for different emotion classes\n",
    "The training time comparison shows a big difference - SVM and GradientBoosting took ~5 minutes while RandomForest took only 5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Continued Model Dev And Fine tuning On Validation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Advanced Model Development and Fine-Tuning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, Flatten, \n",
    "                                    BatchNormalization, Input, GlobalAveragePooling2D,\n",
    "                                    SeparableConv2D, Activation, add, Lambda)\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.1 Hyperparameter Optimization for CNNs\n",
    "\n",
    "def create_improved_cnn(input_shape=(48, 48, 1), num_classes=5, \n",
    "                        filters=(32, 64, 128), kernel_size=(3, 3), \n",
    "                        dropout_rates=(0.25, 0.25, 0.25, 0.5, 0.5),\n",
    "                        use_batch_norm=True, learning_rate=0.001, \n",
    "                        optimizer_name='adam', l2_reg=0.0001):\n",
    "    \"\"\"\n",
    "    Create an improved CNN model with configurable hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input images\n",
    "        num_classes: Number of emotion classes\n",
    "        filters: Tuple of filter counts for each conv block\n",
    "        kernel_size: Size of convolutional kernels\n",
    "        dropout_rates: Dropout rates for each block\n",
    "        use_batch_norm: Whether to use batch normalization\n",
    "        learning_rate: Initial learning rate\n",
    "        optimizer_name: Name of optimizer to use ('adam', 'rmsprop', or 'sgd')\n",
    "        l2_reg: L2 regularization strength\n",
    "        \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First convolutional block\n",
    "    model.add(Conv2D(filters[0], kernel_size, padding='same', \n",
    "                    activation='relu', input_shape=input_shape,\n",
    "                    kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters[0], kernel_size, padding='same', \n",
    "                    activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rates[0]))\n",
    "    \n",
    "    # Second convolutional block\n",
    "    model.add(Conv2D(filters[1], kernel_size, padding='same', \n",
    "                    activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters[1], kernel_size, padding='same', \n",
    "                    activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rates[1]))\n",
    "    \n",
    "    # Third convolutional block\n",
    "    model.add(Conv2D(filters[2], kernel_size, padding='same', \n",
    "                    activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters[2], kernel_size, padding='same', \n",
    "                    activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rates[2]))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rates[3]))\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rates[4]))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Select optimizer\n",
    "    if optimizer_name.lower() == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name.lower() == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_name.lower() == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        print(f\"Unrecognized optimizer: {optimizer_name}. Using Adam.\")\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Creates a focal loss function to address class imbalance more effectively.\n",
    "    \n",
    "    Args:\n",
    "        gamma: Focusing parameter (higher values focus more on hard examples)\n",
    "        alpha: Class balance parameter\n",
    "        \n",
    "    Returns:\n",
    "        Focal loss function compatible with Keras\n",
    "    \"\"\"\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Clip predictions to prevent NaN or Inf values\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        \n",
    "        # Sum over classes and average over samples\n",
    "        return K.mean(K.sum(loss, axis=-1))\n",
    "        \n",
    "    return focal_loss\n",
    "\n",
    "def grid_search_cnn_hyperparameters(X_train, y_train, X_val, y_val, class_weights=None):\n",
    "    \"\"\"\n",
    "    Perform a grid search over CNN hyperparameters using training and validation data only.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels\n",
    "        class_weights: Class weights for imbalanced data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of results for each hyperparameter combination\n",
    "    \"\"\"\n",
    "    # Define hyperparameter grid\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "        'optimizer': ['adam', 'rmsprop'],\n",
    "        'dropout_rates': [\n",
    "            (0.25, 0.25, 0.25, 0.5, 0.5),  # Original\n",
    "            (0.3, 0.3, 0.3, 0.5, 0.5),     # Higher in conv layers\n",
    "            (0.2, 0.2, 0.2, 0.6, 0.6)      # Higher in dense layers\n",
    "        ],\n",
    "        'filters': [\n",
    "            (32, 64, 128),                 # Original\n",
    "            (64, 128, 256),                # More filters\n",
    "            (16, 32, 64)                   # Fewer filters\n",
    "        ],\n",
    "        'use_focal_loss': [False, True]    # Whether to use focal loss\n",
    "    }\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    # Track best model\n",
    "    best_val_acc = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Define training parameters\n",
    "    batch_size = 64\n",
    "    epochs = 30\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Iterate through hyperparameter combinations\n",
    "    param_combinations = []\n",
    "    \n",
    "    # Generate all parameter combinations (subset of full grid)\n",
    "    for lr in param_grid['learning_rate']:\n",
    "        for opt in param_grid['optimizer']:\n",
    "            for dr in [param_grid['dropout_rates'][0]]:  # Just use first dropout config for brevity\n",
    "                for filt in param_grid['filters']:\n",
    "                    for use_focal in param_grid['use_focal_loss']:\n",
    "                        param_combinations.append({\n",
    "                            'learning_rate': lr,\n",
    "                            'optimizer': opt,\n",
    "                            'dropout_rates': dr,\n",
    "                            'filters': filt,\n",
    "                            'use_focal_loss': use_focal\n",
    "                        })\n",
    "    \n",
    "    # Limit to a manageable number of combinations\n",
    "    param_combinations = param_combinations[:6]  # Adjust based on available time/resources\n",
    "    \n",
    "    print(f\"Performing grid search with {len(param_combinations)} parameter combinations\")\n",
    "    \n",
    "    # Iterate through parameter combinations\n",
    "    for i, params in enumerate(param_combinations):\n",
    "        print(f\"\\nTraining model {i+1}/{len(param_combinations)}:\")\n",
    "        print(f\"Parameters: {params}\")\n",
    "        \n",
    "        # Create model\n",
    "        model = create_improved_cnn(\n",
    "            input_shape=X_train.shape[1:],\n",
    "            num_classes=y_train.shape[1],\n",
    "            filters=params['filters'],\n",
    "            dropout_rates=params['dropout_rates'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            optimizer_name=params['optimizer']\n",
    "        )\n",
    "        \n",
    "        # Use focal loss if specified\n",
    "        if params['use_focal_loss']:\n",
    "            model.compile(\n",
    "                optimizer=model.optimizer,\n",
    "                loss=create_focal_loss(gamma=2.0),\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "        \n",
    "        # Train model\n",
    "        start_time = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(X_val, y_val),\n",
    "            class_weight=class_weights,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Evaluate model on validation data only\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "        \n",
    "        # Save results\n",
    "        results[i] = {\n",
    "            'params': params,\n",
    "            'val_accuracy': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'history': history.history,\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        \n",
    "        # Check if this is the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "        \n",
    "        print(f\"Validation accuracy: {val_acc:.4f}, Validation loss: {val_loss:.4f}\")\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "        \n",
    "        # Clear model to free memory\n",
    "        K.clear_session()\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(\"\\nGrid search complete!\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    return results, best_params, best_model\n",
    "\n",
    "def visualize_grid_search_results(results):\n",
    "    \"\"\"\n",
    "    Visualize the results of the grid search.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary of grid search results\n",
    "    \"\"\"\n",
    "    # Extract results\n",
    "    param_indices = list(results.keys())\n",
    "    val_accuracies = [results[i]['val_accuracy'] for i in param_indices]\n",
    "    val_losses = [results[i]['val_loss'] for i in param_indices]\n",
    "    training_times = [results[i]['training_time'] for i in param_indices]\n",
    "    \n",
    "    # Sort by validation accuracy\n",
    "    sorted_indices = np.argsort(val_accuracies)[::-1]\n",
    "    sorted_param_indices = [param_indices[i] for i in sorted_indices]\n",
    "    sorted_val_accs = [val_accuracies[i] for i in sorted_indices]\n",
    "    sorted_val_losses = [val_losses[i] for i in sorted_indices]\n",
    "    sorted_times = [training_times[i] for i in sorted_indices]\n",
    "    \n",
    "    # Create labels for x-axis\n",
    "    labels = [\n",
    "        f\"M{idx}: \" + \n",
    "        f\"LR={results[idx]['params']['learning_rate']}, \" +\n",
    "        f\"Opt={results[idx]['params']['optimizer'][:3]}, \" +\n",
    "        f\"Filt={results[idx]['params']['filters'][0]}\"\n",
    "        for idx in sorted_param_indices\n",
    "    ]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars = plt.bar(range(len(sorted_param_indices)), sorted_val_accs, color='skyblue')\n",
    "    plt.title('Validation Accuracy by Hyperparameter Combination')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.xticks(range(len(sorted_param_indices)), range(1, len(sorted_param_indices) + 1))\n",
    "    \n",
    "    # Add accuracy values on bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "                f\"{sorted_val_accs[i]:.4f}\", ha='center')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(range(len(sorted_param_indices)), sorted_val_losses, color='salmon')\n",
    "    plt.title('Validation Loss by Hyperparameter Combination')\n",
    "    plt.xlabel('Model Configuration')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xticks(range(len(sorted_param_indices)), labels, rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot learning curves for best model\n",
    "    best_idx = sorted_param_indices[0]\n",
    "    history = results[best_idx]['history']\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'], label='Train')\n",
    "    plt.plot(history['val_accuracy'], label='Validation')\n",
    "    plt.title(f'Model Accuracy (Best Configuration)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Train')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.title(f'Model Loss (Best Configuration)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Cross-Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.2 Cross-Validation for Robust Performance Estimation\n",
    "\n",
    "def perform_cross_validation(X_train, y_train, model_fn, n_splits=5, batch_size=64, epochs=30, \n",
    "                            class_weights=None, use_augmentation=True):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation on the emotion recognition model using only training data.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training features and labels\n",
    "        model_fn: Function to create model\n",
    "        n_splits: Number of cross-validation folds\n",
    "        batch_size: Batch size for training\n",
    "        epochs: Maximum number of epochs\n",
    "        class_weights: Class weights for imbalanced data\n",
    "        use_augmentation: Whether to use data augmentation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of cross-validation results\n",
    "    \"\"\"\n",
    "    # Initialize stratified k-fold\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Convert one-hot encoded labels back to class indices for stratification\n",
    "    if len(y_train.shape) > 1 and y_train.shape[1] > 1:\n",
    "        y_indices = np.argmax(y_train, axis=1)\n",
    "    else:\n",
    "        y_indices = y_train\n",
    "    \n",
    "    # Initialize results\n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    fold_histories = []\n",
    "    fold_models = []\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Create data augmentation generator if requested\n",
    "    if use_augmentation:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "    \n",
    "    # Perform k-fold cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_indices)):\n",
    "        print(f\"\\nTraining fold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        \n",
    "        # Handle one-hot encoded labels properly\n",
    "        if len(y_train.shape) > 1 and y_train.shape[1] > 1:\n",
    "            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        else:\n",
    "            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        # Create model\n",
    "        model = model_fn()\n",
    "        \n",
    "        # Train model\n",
    "        if use_augmentation:\n",
    "            # Use data generator with augmentation\n",
    "            train_generator = train_datagen.flow(\n",
    "                X_train_fold, y_train_fold, \n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch=len(X_train_fold) // batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=(X_val_fold, y_val_fold),\n",
    "                class_weight=class_weights,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "        else:\n",
    "            # Train without augmentation\n",
    "            history = model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=(X_val_fold, y_val_fold),\n",
    "                class_weight=class_weights,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "        \n",
    "        # Evaluate model on fold validation data\n",
    "        val_loss, val_acc = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        \n",
    "        # Store results\n",
    "        fold_accuracies.append(val_acc)\n",
    "        fold_losses.append(val_loss)\n",
    "        fold_histories.append(history.history)\n",
    "        fold_models.append(model)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Validation accuracy: {val_acc:.4f}, Validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Calculate average performance\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_loss = np.mean(fold_losses)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    \n",
    "    print(\"\\nCross-validation complete!\")\n",
    "    print(f\"Average validation accuracy: {avg_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    print(f\"Average validation loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'fold_accuracies': fold_accuracies,\n",
    "        'fold_losses': fold_losses,\n",
    "        'fold_histories': fold_histories,\n",
    "        'fold_models': fold_models,\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'avg_loss': avg_loss,\n",
    "        'std_accuracy': std_accuracy\n",
    "    }\n",
    "\n",
    "def visualize_cross_validation_results(cv_results):\n",
    "    \"\"\"\n",
    "    Visualize the results of cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        cv_results: Dictionary of cross-validation results\n",
    "    \"\"\"\n",
    "    # Extract results\n",
    "    fold_accuracies = cv_results['fold_accuracies']\n",
    "    fold_losses = cv_results['fold_losses']\n",
    "    fold_histories = cv_results['fold_histories']\n",
    "    avg_accuracy = cv_results['avg_accuracy']\n",
    "    std_accuracy = cv_results['std_accuracy']\n",
    "    \n",
    "    # Plot fold accuracies\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(1, len(fold_accuracies) + 1), fold_accuracies, color='skyblue')\n",
    "    plt.axhline(y=avg_accuracy, color='r', linestyle='-', label=f'Average: {avg_accuracy:.4f}')\n",
    "    plt.axhline(y=avg_accuracy + std_accuracy, color='r', linestyle='--', alpha=0.5,\n",
    "                label=f'± Std Dev: {std_accuracy:.4f}')\n",
    "    plt.axhline(y=avg_accuracy - std_accuracy, color='r', linestyle='--', alpha=0.5)\n",
    "    plt.title('Validation Accuracy by Fold')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.xticks(range(1, len(fold_accuracies) + 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(1, len(fold_losses) + 1), fold_losses, color='salmon')\n",
    "    plt.axhline(y=cv_results['avg_loss'], color='r', linestyle='-', \n",
    "                label=f'Average: {cv_results[\"avg_loss\"]:.4f}')\n",
    "    plt.title('Validation Loss by Fold')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xticks(range(1, len(fold_losses) + 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot learning curves for each fold\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        plt.plot(history['val_accuracy'], label=f'Fold {i+1}')\n",
    "    plt.title('Validation Accuracy During Training (All Folds)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        plt.plot(history['val_loss'], label=f'Fold {i+1}')\n",
    "    plt.title('Validation Loss During Training (All Folds)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.3 Transfer Learning with Pre-trained Models\n",
    "\n",
    "def create_transfer_learning_model(base_model_name='vgg16', input_shape=(48, 48, 3), \n",
    "                                    num_classes=5, learning_rate=0.0001, trainable_layers=0):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model based on a pre-trained CNN.\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: Name of pre-trained model ('vgg16', 'resnet50', or 'efficientnet')\n",
    "        input_shape: Shape of input images\n",
    "        num_classes: Number of emotion classes\n",
    "        learning_rate: Initial learning rate\n",
    "        trainable_layers: Number of layers to make trainable from the top\n",
    "        \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Handle grayscale input\n",
    "    if input_shape[-1] == 1:\n",
    "        # Create a Lambda layer to convert grayscale to RGB\n",
    "        preprocessing_layer = Lambda(lambda x: K.repeat_elements(x, 3, axis=-1))\n",
    "        input_rgb_shape = (input_shape[0], input_shape[1], 3)\n",
    "    else:\n",
    "        preprocessing_layer = None\n",
    "        input_rgb_shape = input_shape\n",
    "    \n",
    "    # Load pre-trained base model\n",
    "    if base_model_name.lower() == 'vgg16':\n",
    "        base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_rgb_shape)\n",
    "    elif base_model_name.lower() == 'resnet50':\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_rgb_shape)\n",
    "    elif base_model_name.lower() == 'efficientnet':\n",
    "        base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_rgb_shape)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported base model: {base_model_name}\")\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Make some layers trainable if requested\n",
    "    if trainable_layers > 0:\n",
    "        for layer in base_model.layers[-trainable_layers:]:\n",
    "            layer.trainable = True\n",
    "    \n",
    "    # Create full model\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Apply preprocessing if needed\n",
    "    if preprocessing_layer is not None:\n",
    "        x = preprocessing_layer(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "    \n",
    "    # Pass inputs through base model\n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def fine_tune_transfer_learning_model(model, X_train, y_train, X_val, y_val, \n",
    "                                        batch_size=32, epochs=20, class_weights=None):\n",
    "    \"\"\"\n",
    "    Fine-tune a transfer learning model using training and validation data only.\n",
    "    \n",
    "    Args:\n",
    "        model: Pre-trained transfer learning model\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels\n",
    "        batch_size: Batch size for training\n",
    "        epochs: Maximum number of epochs\n",
    "        class_weights: Class weights for imbalanced data\n",
    "        \n",
    "    Returns:\n",
    "        Fine-tuned model and training history\n",
    "    \"\"\"\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Define data augmentation generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Fine-tuning transfer learning model...\")\n",
    "    \n",
    "    # Create generator for training\n",
    "    train_generator = train_datagen.flow(\n",
    "        X_train, y_train, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_model(models, X_val, y_val, method='average'):\n",
    "    \"\"\"\n",
    "    Create an ensemble of multiple emotion recognition models using validation data.\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained models to ensemble\n",
    "        X_val, y_val: Validation data for calibration\n",
    "        method: Ensemble method ('average', 'weighted', or 'stacking')\n",
    "        \n",
    "    Returns:\n",
    "        Ensemble model function and evaluation metrics on validation data\n",
    "    \"\"\"\n",
    "    num_models = len(models)\n",
    "    num_classes = y_val.shape[1]\n",
    "    \n",
    "    # Compute predictions on validation set\n",
    "    print(\"Computing validation predictions for ensemble calibration...\")\n",
    "    val_preds = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Model {i+1}/{num_models}\")\n",
    "        val_pred = model.predict(X_val)\n",
    "        val_preds.append(val_pred)\n",
    "    \n",
    "    if method == 'average':\n",
    "        # Simple averaging ensemble\n",
    "        print(\"Creating averaging ensemble...\")\n",
    "        \n",
    "        # Define ensemble function\n",
    "        def ensemble_predict(X):\n",
    "            # Get predictions from each model\n",
    "            preds = []\n",
    "            for model in models:\n",
    "                pred = model.predict(X)\n",
    "                preds.append(pred)\n",
    "            \n",
    "            # Average predictions\n",
    "            ensemble_pred = np.mean(preds, axis=0)\n",
    "            return ensemble_pred\n",
    "        \n",
    "        # Evaluate on validation data\n",
    "        ensemble_val_pred = np.mean(val_preds, axis=0)\n",
    "        \n",
    "    elif method == 'weighted':\n",
    "        # Weighted averaging based on validation performance\n",
    "        print(\"Creating weighted ensemble...\")\n",
    "        \n",
    "        # Calculate model weights based on validation accuracy\n",
    "        model_accuracies = []\n",
    "        for i, pred in enumerate(val_preds):\n",
    "            acc = np.mean(np.argmax(pred, axis=1) == np.argmax(y_val, axis=1))\n",
    "            model_accuracies.append(acc)\n",
    "            print(f\"Model {i+1}: Validation accuracy = {acc:.4f}\")\n",
    "        \n",
    "        # Normalize accuracies to get weights\n",
    "        model_weights = np.array(model_accuracies) / np.sum(model_accuracies)\n",
    "        print(\"Model weights:\", model_weights)\n",
    "        \n",
    "        # Define ensemble function\n",
    "        def ensemble_predict(X):\n",
    "            # Get predictions from each model\n",
    "            preds = []\n",
    "            for model in models:\n",
    "                pred = model.predict(X)\n",
    "                preds.append(pred)\n",
    "            \n",
    "            # Compute weighted average\n",
    "            ensemble_pred = np.zeros_like(preds[0])\n",
    "            for i, pred in enumerate(preds):\n",
    "                ensemble_pred += model_weights[i] * pred\n",
    "                \n",
    "            return ensemble_pred\n",
    "        \n",
    "        # Evaluate on validation data\n",
    "        ensemble_val_pred = np.zeros_like(val_preds[0])\n",
    "        for i, pred in enumerate(val_preds):\n",
    "            ensemble_val_pred += model_weights[i] * pred\n",
    "            \n",
    "    elif method == 'stacking':\n",
    "        # Stacking ensemble using a meta-learner\n",
    "        print(\"Creating stacking ensemble...\")\n",
    "        \n",
    "        # Prepare meta-learner training data\n",
    "        meta_X = np.concatenate(val_preds, axis=1)\n",
    "        meta_y = y_val\n",
    "        \n",
    "        # Train a simple meta-learner (logistic regression)\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        meta_learner = LogisticRegression(multi_class='multinomial', max_iter=1000, C=0.1)\n",
    "        meta_learner.fit(meta_X, np.argmax(meta_y, axis=1))\n",
    "        \n",
    "        # Define ensemble function\n",
    "        def ensemble_predict(X):\n",
    "            # Get predictions from each model\n",
    "            preds = []\n",
    "            for model in models:\n",
    "                pred = model.predict(X)\n",
    "                preds.append(pred)\n",
    "            \n",
    "            # Combine predictions for meta-learner\n",
    "            meta_X_pred = np.concatenate(preds, axis=1)\n",
    "            \n",
    "            # Get meta-learner predictions\n",
    "            meta_pred_class = meta_learner.predict(meta_X_pred)\n",
    "            meta_pred_prob = meta_learner.predict_proba(meta_X_pred)\n",
    "            \n",
    "            # Convert to one-hot encoded format\n",
    "            ensemble_pred = np.zeros((len(meta_pred_class), num_classes))\n",
    "            for i, cls in enumerate(meta_pred_class):\n",
    "                ensemble_pred[i, cls] = 1\n",
    "                \n",
    "            return meta_pred_prob\n",
    "        \n",
    "        # Evaluate on validation data\n",
    "        meta_X_val = np.concatenate(val_preds, axis=1)\n",
    "        ensemble_val_pred = meta_learner.predict_proba(meta_X_val)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ensemble method: {method}\")\n",
    "    \n",
    "    # Evaluate ensemble on validation data only\n",
    "    ensemble_val_acc = np.mean(np.argmax(ensemble_val_pred, axis=1) == np.argmax(y_val, axis=1))\n",
    "    print(f\"Ensemble validation accuracy: {ensemble_val_acc:.4f}\")\n",
    "    \n",
    "    # Calculate class-wise metrics\n",
    "    ensemble_val_pred_class = np.argmax(ensemble_val_pred, axis=1)\n",
    "    y_val_class = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    report = classification_report(y_val_class, ensemble_val_pred_class, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_val_class, ensemble_val_pred_class)\n",
    "    \n",
    "    # Return ensemble function and evaluation metrics\n",
    "    return ensemble_predict, {\n",
    "        'accuracy': ensemble_val_acc,\n",
    "        'report': report,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'method': method\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ensemble_performance(ensemble_metrics, individual_metrics, emotion_map=None):\n",
    "    \"\"\"\n",
    "    Visualize the performance of the ensemble compared to individual models on validation data.\n",
    "    \n",
    "    Args:\n",
    "        ensemble_metrics: Metrics from the ensemble model\n",
    "        individual_metrics: List of metrics from individual models\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Extract accuracies\n",
    "    model_accs = [metrics['accuracy'] for metrics in individual_metrics]\n",
    "    model_accs.append(ensemble_metrics['accuracy'])\n",
    "    \n",
    "    # Create labels\n",
    "    model_labels = [f\"Model {i+1}\" for i in range(len(individual_metrics))]\n",
    "    model_labels.append(f\"Ensemble ({ensemble_metrics['method']})\")\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_labels, model_accs, color=['skyblue'] * len(individual_metrics) + ['orange'])\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add accuracy values on bars\n",
    "    for i, v in enumerate(model_accs):\n",
    "        plt.text(i, v + 0.01, f\"{v:.4f}\", ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot class-wise F1 scores\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Extract F1 scores\n",
    "    num_classes = len(emotion_map)\n",
    "    f1_scores = np.zeros((len(model_labels), num_classes))\n",
    "    \n",
    "    for i, metrics in enumerate(individual_metrics):\n",
    "        report = metrics['report']\n",
    "        for j in range(num_classes):\n",
    "            if str(j) in report:\n",
    "                f1_scores[i, j] = report[str(j)]['f1-score']\n",
    "    \n",
    "    # Add ensemble F1 scores\n",
    "    ensemble_report = ensemble_metrics['report']\n",
    "    for j in range(num_classes):\n",
    "        if str(j) in ensemble_report:\n",
    "            f1_scores[-1, j] = ensemble_report[str(j)]['f1-score']\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(f1_scores, annot=True, fmt='.3f', cmap='YlGnBu',\n",
    "                xticklabels=[emotion_map[i] for i in range(num_classes)],\n",
    "                yticklabels=model_labels)\n",
    "    plt.xlabel('Emotion Class')\n",
    "    plt.ylabel('Model')\n",
    "    plt.title('Class-wise F1 Scores Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot confusion matrix for ensemble\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(ensemble_metrics['conf_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[emotion_map[i] for i in range(num_classes)],\n",
    "                yticklabels=[emotion_map[i] for i in range(num_classes)])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - Ensemble ({ensemble_metrics[\"method\"]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Error analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_error_analysis(model, X_val, y_val, emotion_map=None, n_samples=20):\n",
    "    \"\"\"\n",
    "    Perform detailed error analysis on validation data to understand model weaknesses.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_val: Validation features\n",
    "        y_val: Validation labels (one-hot encoded)\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "        n_samples: Number of misclassified samples to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of error analysis results\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    print(\"Performing error analysis on validation data...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Identify misclassified samples\n",
    "    misclassified_indices = np.where(y_pred != y_true)[0]\n",
    "    print(f\"Found {len(misclassified_indices)} misclassified samples out of {len(y_val)} ({len(misclassified_indices)/len(y_val)*100:.2f}%)\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    norm_conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Analyze error patterns\n",
    "    error_patterns = []\n",
    "    \n",
    "    for true_class in range(len(emotion_map)):\n",
    "        for pred_class in range(len(emotion_map)):\n",
    "            if true_class != pred_class and conf_matrix[true_class, pred_class] > 0:\n",
    "                error_rate = norm_conf_matrix[true_class, pred_class]\n",
    "                error_patterns.append({\n",
    "                    'true_class': true_class,\n",
    "                    'true_emotion': emotion_map[true_class],\n",
    "                    'pred_class': pred_class,\n",
    "                    'pred_emotion': emotion_map[pred_class],\n",
    "                    'count': conf_matrix[true_class, pred_class],\n",
    "                    'error_rate': error_rate\n",
    "                })\n",
    "    \n",
    "    # Sort error patterns by count\n",
    "    error_patterns = sorted(error_patterns, key=lambda x: x['count'], reverse=True)\n",
    "    \n",
    "    # Print top error patterns\n",
    "    print(\"\\nTop error patterns:\")\n",
    "    for i, pattern in enumerate(error_patterns[:5]):\n",
    "        print(f\"{i+1}. {pattern['true_emotion']} → {pattern['pred_emotion']}: \"\n",
    "                f\"{pattern['count']} samples ({pattern['error_rate']*100:.2f}% of {pattern['true_emotion']} samples)\")\n",
    "    \n",
    "    # Select random misclassified samples for analysis\n",
    "    if len(misclassified_indices) > n_samples:\n",
    "        sample_indices = np.random.choice(misclassified_indices, n_samples, replace=False)\n",
    "    else:\n",
    "        sample_indices = misclassified_indices\n",
    "    \n",
    "    samples = []\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        true_class = y_true[idx]\n",
    "        pred_class = y_pred[idx]\n",
    "        pred_prob = y_pred_prob[idx, pred_class]\n",
    "        true_prob = y_pred_prob[idx, true_class]\n",
    "        \n",
    "        sample = {\n",
    "            'index': idx,\n",
    "            'image': X_val[idx],\n",
    "            'true_class': true_class,\n",
    "            'true_emotion': emotion_map[true_class],\n",
    "            'pred_class': pred_class,\n",
    "            'pred_emotion': emotion_map[pred_class],\n",
    "            'pred_prob': pred_prob,\n",
    "            'true_prob': true_prob,\n",
    "            'confidence_gap': pred_prob - true_prob\n",
    "        }\n",
    "        \n",
    "        samples.append(sample)\n",
    "    \n",
    "    # Analyze confidence patterns\n",
    "    correct_confidences = y_pred_prob[y_pred == y_true, y_true[y_pred == y_true]]\n",
    "    incorrect_confidences = y_pred_prob[y_pred != y_true, y_pred[y_pred != y_true]]\n",
    "    \n",
    "    # Class-specific confidence analysis\n",
    "    class_confidences = {}\n",
    "    \n",
    "    for cls in range(len(emotion_map)):\n",
    "        # Correct predictions for this class\n",
    "        correct_indices = np.where((y_pred == y_true) & (y_true == cls))[0]\n",
    "        if len(correct_indices) > 0:\n",
    "            correct_conf = y_pred_prob[correct_indices, cls]\n",
    "        else:\n",
    "            correct_conf = np.array([])\n",
    "        \n",
    "        # Incorrect predictions as this class\n",
    "        incorrect_as_indices = np.where((y_pred != y_true) & (y_pred == cls))[0]\n",
    "        if len(incorrect_as_indices) > 0:\n",
    "            incorrect_as_conf = y_pred_prob[incorrect_as_indices, cls]\n",
    "        else:\n",
    "            incorrect_as_conf = np.array([])\n",
    "        \n",
    "        # Incorrect predictions of this class\n",
    "        incorrect_of_indices = np.where((y_pred != y_true) & (y_true == cls))[0]\n",
    "        if len(incorrect_of_indices) > 0:\n",
    "            incorrect_of_conf = y_pred_prob[incorrect_of_indices, y_pred[incorrect_of_indices]]\n",
    "        else:\n",
    "            incorrect_of_conf = np.array([])\n",
    "        \n",
    "        class_confidences[cls] = {\n",
    "            'correct': correct_conf,\n",
    "            'incorrect_as': incorrect_as_conf,\n",
    "            'incorrect_of': incorrect_of_conf\n",
    "        }\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'norm_conf_matrix': norm_conf_matrix,\n",
    "        'error_patterns': error_patterns,\n",
    "        'samples': samples,\n",
    "        'correct_confidences': correct_confidences,\n",
    "        'incorrect_confidences': incorrect_confidences,\n",
    "        'class_confidences': class_confidences\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_error_analysis(error_results, emotion_map=None):\n",
    "    \"\"\"\n",
    "    Visualize the results of error analysis.\n",
    "    \n",
    "    Args:\n",
    "        error_results: Dictionary of error analysis results\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(error_results['norm_conf_matrix'], annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=[emotion_map[i] for i in range(len(emotion_map))],\n",
    "                yticklabels=[emotion_map[i] for i in range(len(emotion_map))])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot top error patterns\n",
    "    top_patterns = error_results['error_patterns'][:5]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(\n",
    "        [f\"{p['true_emotion']} → {p['pred_emotion']}\" for p in top_patterns],\n",
    "        [p['count'] for p in top_patterns],\n",
    "        color='salmon'\n",
    "    )\n",
    "    plt.title('Top Error Patterns')\n",
    "    plt.xlabel('Error Pattern')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot confidence distributions\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(error_results['correct_confidences'], bins=20, alpha=0.7, label='Correct predictions', color='green')\n",
    "    plt.hist(error_results['incorrect_confidences'], bins=20, alpha=0.7, label='Incorrect predictions', color='red')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Confidence Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot misclassified samples\n",
    "    plt.figure(figsize=(15, min(len(error_results['samples']), 10) * 2))\n",
    "    \n",
    "    for i, sample in enumerate(error_results['samples'][:10]):\n",
    "        img = sample['image']\n",
    "        if len(img.shape) == 3 and img.shape[-1] == 1:\n",
    "            img = img.reshape(img.shape[0], img.shape[1])\n",
    "        \n",
    "        plt.subplot(min(len(error_results['samples']), 10), 2, i * 2 + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"True: {sample['true_emotion']}, Pred: {sample['pred_emotion']}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Plot prediction probabilities\n",
    "        plt.subplot(min(len(error_results['samples']), 10), 2, i * 2 + 2)\n",
    "        \n",
    "        probs = np.zeros(len(emotion_map))\n",
    "        for j in range(len(emotion_map)):\n",
    "            if j == sample['true_class']:\n",
    "                probs[j] = sample['true_prob']\n",
    "            elif j == sample['pred_class']:\n",
    "                probs[j] = sample['pred_prob']\n",
    "            # Other classes' probabilities not shown for clarity\n",
    "        \n",
    "        colors = ['red' if j != sample['true_class'] else 'green' for j in range(len(emotion_map))]\n",
    "        plt.bar(range(len(emotion_map)), probs, color=colors)\n",
    "        plt.xticks(range(len(emotion_map)), [emotion_map[i] for i in range(len(emotion_map))], rotation=45, ha='right')\n",
    "        plt.xlabel('Emotion')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot class-wise confidence analysis\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, cls in enumerate(range(len(emotion_map))):\n",
    "        confidences = error_results['class_confidences'][cls]\n",
    "        \n",
    "        plt.subplot(3, 2, i+1)\n",
    "        \n",
    "        if len(confidences['correct']) > 0:\n",
    "            plt.hist(confidences['correct'], bins=10, alpha=0.7, label='Correct', color='green')\n",
    "        \n",
    "        if len(confidences['incorrect_as']) > 0:\n",
    "            plt.hist(confidences['incorrect_as'], bins=10, alpha=0.7, label='Falsely predicted', color='red')\n",
    "        \n",
    "        if len(confidences['incorrect_of']) > 0:\n",
    "            plt.hist(confidences['incorrect_of'], bins=10, alpha=0.7, label='Missed', color='orange')\n",
    "        \n",
    "        plt.title(f\"Confidence Analysis: {emotion_map[cls]}\")\n",
    "        plt.xlabel('Confidence')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_model_for_common_errors(model, X_train, y_train, X_val, y_val, \n",
    "                                    error_results, emotion_map=None, \n",
    "                                    batch_size=64, epochs=30):\n",
    "    \"\"\"\n",
    "    Refine the model to address common error patterns using training and validation data.\n",
    "    Fixed to avoid class_weight issue with generators.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model to refine\n",
    "        X_train, y_train: Training data and labels\n",
    "        X_val, y_val: Validation data and labels\n",
    "        error_results: Error analysis results\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "        batch_size: Batch size for training\n",
    "        epochs: Maximum number of epochs\n",
    "        \n",
    "    Returns:\n",
    "        Refined model and training history\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Identify most common error patterns\n",
    "    top_errors = error_results['error_patterns'][:3]\n",
    "    \n",
    "    print(\"Refining model to address common error patterns:\")\n",
    "    for i, pattern in enumerate(top_errors):\n",
    "        print(f\"{i+1}. {pattern['true_emotion']} → {pattern['pred_emotion']}: \"\n",
    "                f\"{pattern['count']} samples ({pattern['error_rate']*100:.2f}% of {pattern['true_emotion']} samples)\")\n",
    "    \n",
    "    # Create focused data augmentation for problematic classes\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Create focused dataset with more samples of problematic classes\n",
    "    problem_classes = [pattern['true_class'] for pattern in top_errors]\n",
    "    \n",
    "    # Identify samples from problematic classes\n",
    "    y_train_indices = np.argmax(y_train, axis=1)\n",
    "    problem_indices = []\n",
    "    for cls in problem_classes:\n",
    "        cls_indices = np.where(y_train_indices == cls)[0]\n",
    "        problem_indices.extend(cls_indices)\n",
    "    \n",
    "    # Instead of using custom generator with class weights,\n",
    "    # we'll oversample the problem classes in the dataset\n",
    "    X_train_enhanced = X_train.copy()\n",
    "    y_train_enhanced = y_train.copy()\n",
    "    \n",
    "    # Duplicate problem samples (2x)\n",
    "    X_problem = X_train[problem_indices]\n",
    "    y_problem = y_train[problem_indices]\n",
    "    \n",
    "    # Add duplicates\n",
    "    X_train_enhanced = np.concatenate([X_train_enhanced, X_problem], axis=0)\n",
    "    y_train_enhanced = np.concatenate([y_train_enhanced, y_problem], axis=0)\n",
    "    \n",
    "    print(f\"Enhanced training set: {len(X_train)} → {len(X_train_enhanced)} samples\")\n",
    "    print(f\"Problem classes oversampled: {[emotion_map[cls] for cls in problem_classes]}\")\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Create data generator for augmentation\n",
    "    train_gen = train_datagen.flow(\n",
    "        X_train_enhanced, y_train_enhanced, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Refine model\n",
    "    print(\"\\nRefining model...\")\n",
    "    \n",
    "    # Train model using generator without class_weights\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=len(X_train_enhanced) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_predictions_on_samples(model, X_sample, emotion_map=None, true_emotions=None, n_samples=10):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on a small set of sample images.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_sample: Sample images to visualize\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "        true_emotions: True emotion labels (optional)\n",
    "        n_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    # Limit to n_samples\n",
    "    if len(X_sample) > n_samples:\n",
    "        indices = np.random.choice(len(X_sample), n_samples, replace=False)\n",
    "        X_display = X_sample[indices]\n",
    "        if true_emotions is not None:\n",
    "            true_emotions = [true_emotions[i] for i in indices]\n",
    "    else:\n",
    "        X_display = X_sample\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_display)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Visualize results\n",
    "    n_cols = min(5, len(X_display))\n",
    "    n_rows = (len(X_display) + n_cols - 1) // n_cols\n",
    "    \n",
    "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "    \n",
    "    for i, img in enumerate(X_display):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        # Handle different image formats\n",
    "        if len(img.shape) == 3 and img.shape[-1] == 1:\n",
    "            img = img.reshape(img.shape[0], img.shape[1])\n",
    "        \n",
    "        plt.imshow(img, cmap='gray')\n",
    "        \n",
    "        pred_class = y_pred_class[i]\n",
    "        pred_emotion = emotion_map[pred_class]\n",
    "        pred_confidence = y_pred[i, pred_class]\n",
    "        \n",
    "        title = f\"Pred: {pred_emotion}\\nConf: {pred_confidence:.2f}\"\n",
    "        if true_emotions is not None:\n",
    "            title = f\"True: {true_emotions[i]}\\n{title}\"\n",
    "            \n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complete_emotion_recognition_pipeline(model, emotion_map=None, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Create a complete pipeline for emotion recognition.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "        confidence_threshold: Threshold for confidence to accept prediction\n",
    "        \n",
    "    Returns:\n",
    "        Pipeline function\n",
    "    \"\"\"\n",
    "    if emotion_map is None:\n",
    "        emotion_map = {\n",
    "            0: 'Positive',\n",
    "            1: 'Negative-High Arousal',\n",
    "            2: 'Negative-Low Arousal',\n",
    "            3: 'Surprise',\n",
    "            4: 'Neutral'\n",
    "        }\n",
    "    \n",
    "    def preprocess_image(img):\n",
    "        \"\"\"Preprocess a single image for prediction.\"\"\"\n",
    "        # Check if image needs to be converted to grayscale\n",
    "        if len(img.shape) == 3 and img.shape[2] > 1:\n",
    "            from skimage.color import rgb2gray\n",
    "            img = rgb2gray(img)\n",
    "        \n",
    "        # Resize to expected dimensions\n",
    "        from skimage.transform import resize\n",
    "        img = resize(img, (48, 48), anti_aliasing=True)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if img.max() > 1.0:\n",
    "            img = img / 255.0\n",
    "        \n",
    "        # Add batch dimension and channel dimension\n",
    "        img = img.reshape(1, 48, 48, 1)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def predict_emotion(img):\n",
    "        \"\"\"Predict emotion from an image.\"\"\"\n",
    "        # Preprocess image\n",
    "        processed_img = preprocess_image(img)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred_probs = model.predict(processed_img)[0]\n",
    "        pred_class = np.argmax(pred_probs)\n",
    "        pred_confidence = pred_probs[pred_class]\n",
    "        \n",
    "        # Check confidence\n",
    "        if pred_confidence >= confidence_threshold:\n",
    "            emotion = emotion_map[pred_class]\n",
    "            result = {\n",
    "                'emotion': emotion,\n",
    "                'confidence': pred_confidence,\n",
    "                'emotion_probabilities': {emotion_map[i]: float(pred_probs[i]) for i in range(len(emotion_map))}\n",
    "            }\n",
    "        else:\n",
    "            # Low confidence, return uncertain result\n",
    "            result = {\n",
    "                'emotion': 'Uncertain',\n",
    "                'confidence': pred_confidence,\n",
    "                'emotion_probabilities': {emotion_map[i]: float(pred_probs[i]) for i in range(len(emotion_map))}\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_image_batch(images):\n",
    "        \"\"\"Process a batch of images.\"\"\"\n",
    "        # Preprocess images\n",
    "        processed_images = np.array([preprocess_image(img)[0] for img in images])\n",
    "        \n",
    "        # Get predictions\n",
    "        pred_probs = model.predict(processed_images)\n",
    "        pred_classes = np.argmax(pred_probs, axis=1)\n",
    "        pred_confidences = [pred_probs[i, pred_classes[i]] for i in range(len(pred_classes))]\n",
    "        \n",
    "        # Create results\n",
    "        results = []\n",
    "        for i in range(len(images)):\n",
    "            if pred_confidences[i] >= confidence_threshold:\n",
    "                emotion = emotion_map[pred_classes[i]]\n",
    "            else:\n",
    "                emotion = 'Uncertain'\n",
    "                \n",
    "            result = {\n",
    "                'emotion': emotion,\n",
    "                'confidence': pred_confidences[i],\n",
    "                'emotion_probabilities': {emotion_map[j]: float(pred_probs[i, j]) for j in range(len(emotion_map))}\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # Return pipeline functions\n",
    "    return {\n",
    "        'predict_emotion': predict_emotion,\n",
    "        'process_image_batch': process_image_batch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_export_model(model, model_name, emotion_map, preprocessing_info):\n",
    "    \"\"\"\n",
    "    Save and export the trained model for future use.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        model_name: Name for saving the model\n",
    "        emotion_map: Mapping from class indices to emotion names\n",
    "        preprocessing_info: Dictionary of preprocessing parameters\n",
    "        \n",
    "    Returns:\n",
    "        Path to saved model\n",
    "    \"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = 'models'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(save_dir, f\"{model_name}.h5\")\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'emotion_map': emotion_map,\n",
    "        'preprocessing_info': preprocessing_info,\n",
    "        'model_name': model_name,\n",
    "        'input_shape': model.input_shape[1:],\n",
    "        'output_shape': model.output_shape[1:],\n",
    "        'date_trained': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    metadata_path = os.path.join(save_dir, f\"{model_name}_metadata.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    print(f\"Metadata saved to {metadata_path}\")\n",
    "    \n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_section5_pipeline(processed_data=None):\n",
    "    \"\"\"\n",
    "    Run the complete Section 5 pipeline following proper methodology.\n",
    "    \n",
    "    Args:\n",
    "        processed_data: Dictionary of preprocessed data from previous sections\n",
    "    \n",
    "    Steps:\n",
    "    1. Hyperparameter optimization using training and validation data\n",
    "    2. Cross-validation for robust performance estimation\n",
    "    3. Transfer learning for improved feature extraction\n",
    "    4. Ensemble methods to combine model strengths\n",
    "    5. Error analysis to identify weaknesses\n",
    "    6. Model refinement based on error analysis\n",
    "    7. Final model selection based on validation performance\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of results and the final selected model\n",
    "    \"\"\"\n",
    "    if processed_data is None:\n",
    "        print(\"No processed data provided. Please run previous sections first.\")\n",
    "        return\n",
    "    \n",
    "    # 1. Hyperparameter Optimization\n",
    "    print(\"\\n========== 5.1 Hyperparameter Optimization ==========\")\n",
    "    \n",
    "    grid_results, best_params, best_hp_model = grid_search_cnn_hyperparameters(\n",
    "        processed_data['X_train_aug_cnn'],\n",
    "        processed_data['y_train_aug_onehot'],\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        class_weights=processed_data['class_weights']\n",
    "    )\n",
    "    \n",
    "    visualize_grid_search_results(grid_results)\n",
    "    \n",
    "    # 2. Cross-Validation\n",
    "    print(\"\\n========== 5.2 Cross-Validation ==========\")\n",
    "    \n",
    "    # Create model with best parameters\n",
    "    def create_best_model():\n",
    "        return create_improved_cnn(\n",
    "            input_shape=processed_data['X_train_cnn'].shape[1:],\n",
    "            num_classes=processed_data['y_train_5class_onehot'].shape[1],\n",
    "            filters=best_params['filters'],\n",
    "            dropout_rates=best_params['dropout_rates'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            optimizer_name=best_params['optimizer']\n",
    "        )\n",
    "    \n",
    "    # Only use training data for cross-validation, splitting into train/val within CV folds\n",
    "    cv_results = perform_cross_validation(\n",
    "        processed_data['X_train_aug_cnn'],\n",
    "        processed_data['y_train_aug_onehot'],\n",
    "        create_best_model,\n",
    "        n_splits=5,\n",
    "        batch_size=64,\n",
    "        epochs=30,\n",
    "        class_weights=processed_data['class_weights'],\n",
    "        use_augmentation=True\n",
    "    )\n",
    "    \n",
    "    visualize_cross_validation_results(cv_results)\n",
    "    \n",
    "    # Get the best CV model based on validation accuracy\n",
    "    best_cv_model = cv_results['fold_models'][np.argmax(cv_results['fold_accuracies'])]\n",
    "    \n",
    "    # 3. Transfer Learning\n",
    "    print(\"\\n========== 5.3 Transfer Learning ==========\")\n",
    "    \n",
    "    # Create transfer learning model\n",
    "    transfer_model = create_transfer_learning_model(\n",
    "        base_model_name='vgg16',\n",
    "        input_shape=processed_data['X_train_cnn'].shape[1:],\n",
    "        num_classes=processed_data['y_train_5class_onehot'].shape[1],\n",
    "        learning_rate=0.0001,\n",
    "        trainable_layers=5  # Fine-tune top 5 layers\n",
    "    )\n",
    "    \n",
    "    # Fine-tune model on training data, validating on validation data\n",
    "    fine_tuned_model, transfer_history = fine_tune_transfer_learning_model(\n",
    "        transfer_model,\n",
    "        processed_data['X_train_aug_cnn'],\n",
    "        processed_data['y_train_aug_onehot'],\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        batch_size=32,\n",
    "        epochs=20,\n",
    "        class_weights=processed_data['class_weights']\n",
    "    )\n",
    "    \n",
    "    # Visualize training history\n",
    "    visualize_training_history(transfer_history, title=\"Transfer Learning Model History\")\n",
    "    \n",
    "    # Evaluate on validation data\n",
    "    val_preds_transfer = fine_tuned_model.predict(processed_data['X_val_cnn'])\n",
    "    val_preds_transfer_class = np.argmax(val_preds_transfer, axis=1)\n",
    "    val_true_class = np.argmax(processed_data['y_val_5class_onehot'], axis=1)\n",
    "    \n",
    "    transfer_val_accuracy = np.mean(val_preds_transfer_class == val_true_class)\n",
    "    transfer_val_report = classification_report(val_true_class, val_preds_transfer_class, output_dict=True)\n",
    "    transfer_val_conf_matrix = confusion_matrix(val_true_class, val_preds_transfer_class)\n",
    "    \n",
    "    print(f\"Transfer Learning Validation Accuracy: {transfer_val_accuracy:.4f}\")\n",
    "    \n",
    "    transfer_val_metrics = {\n",
    "        'accuracy': transfer_val_accuracy,\n",
    "        'report': transfer_val_report,\n",
    "        'conf_matrix': transfer_val_conf_matrix\n",
    "    }\n",
    "    \n",
    "    # 4. Ensemble Methods\n",
    "    print(\"\\n========== 5.4 Ensemble Methods ==========\")\n",
    "    \n",
    "    # Create another instance of the best model and train it on the full training set\n",
    "    third_model = create_best_model()\n",
    "    third_model.fit(\n",
    "        processed_data['X_train_aug_cnn'],\n",
    "        processed_data['y_train_aug_onehot'],\n",
    "        batch_size=64,\n",
    "        epochs=20,\n",
    "        validation_data=(processed_data['X_val_cnn'], processed_data['y_val_5class_onehot']),\n",
    "        class_weight=processed_data['class_weights'],\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate all individual models on validation data\n",
    "    models = [best_hp_model, best_cv_model, fine_tuned_model, third_model]\n",
    "    model_names = [\"Hyperparameter Optimized\", \"Best CV\", \"Transfer Learning\", \"Additional Model\"]\n",
    "    individual_val_metrics = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"\\nEvaluating {model_names[i]} on validation set...\")\n",
    "        val_preds = model.predict(processed_data['X_val_cnn'])\n",
    "        val_preds_class = np.argmax(val_preds, axis=1)\n",
    "        \n",
    "        val_accuracy = np.mean(val_preds_class == val_true_class)\n",
    "        val_report = classification_report(val_true_class, val_preds_class, output_dict=True)\n",
    "        val_conf_matrix = confusion_matrix(val_true_class, val_preds_class)\n",
    "        \n",
    "        print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        individual_val_metrics.append({\n",
    "            'name': model_names[i],\n",
    "            'accuracy': val_accuracy,\n",
    "            'report': val_report,\n",
    "            'conf_matrix': val_conf_matrix\n",
    "        })\n",
    "    \n",
    "    # Create ensemble using weighted method\n",
    "    ensemble_predict, ensemble_val_metrics = create_ensemble_model(\n",
    "        models,\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        method='weighted'\n",
    "    )\n",
    "    \n",
    "    # Add name to ensemble metrics\n",
    "    ensemble_val_metrics['name'] = \"Ensemble (weighted)\"\n",
    "    \n",
    "    # Compare all models on validation data\n",
    "    all_val_metrics = individual_val_metrics + [ensemble_val_metrics]\n",
    "    \n",
    "    # Find the best model based on validation accuracy\n",
    "    best_model_idx = np.argmax([m['accuracy'] for m in all_val_metrics])\n",
    "    best_model_name = all_val_metrics[best_model_idx]['name']\n",
    "    \n",
    "    print(f\"\\nBest model based on validation accuracy: {best_model_name} with \"\n",
    "            f\"accuracy {all_val_metrics[best_model_idx]['accuracy']:.4f}\")\n",
    "    \n",
    "    # Visualize ensemble performance\n",
    "    visualize_ensemble_performance(\n",
    "        ensemble_val_metrics,\n",
    "        individual_val_metrics,\n",
    "        emotion_map=processed_data['new_emotion_map']\n",
    "    )\n",
    "    \n",
    "    # 5. Error Analysis\n",
    "    print(\"\\n========== 5.5 Error Analysis ==========\")\n",
    "    \n",
    "    # Use the best individual model for error analysis\n",
    "    if best_model_name == \"Ensemble (weighted)\":\n",
    "        # For error analysis we need a model object, not just a prediction function\n",
    "        # So we'll use the best individual model instead\n",
    "        best_individual_idx = np.argmax([m['accuracy'] for m in individual_val_metrics])\n",
    "        model_for_analysis = models[best_individual_idx]\n",
    "        print(f\"Using {model_names[best_individual_idx]} for error analysis...\")\n",
    "    else:\n",
    "        model_idx = model_names.index(best_model_name)\n",
    "        model_for_analysis = models[model_idx]\n",
    "        print(f\"Using {best_model_name} for error analysis...\")\n",
    "    \n",
    "    # Perform error analysis on validation data\n",
    "    error_results = perform_error_analysis(\n",
    "        model_for_analysis,\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        emotion_map=processed_data['new_emotion_map'],\n",
    "        n_samples=10\n",
    "    )\n",
    "    \n",
    "    visualize_error_analysis(error_results, processed_data['new_emotion_map'])\n",
    "    \n",
    "    # 6. Refine model based on error analysis\n",
    "    print(\"\\n========== 5.6 Model Refinement ==========\")\n",
    "    \n",
    "    refined_model, refinement_history = refine_model_for_common_errors(\n",
    "        model_for_analysis,\n",
    "        processed_data['X_train_aug_cnn'],\n",
    "        processed_data['y_train_aug_onehot'],\n",
    "        processed_data['X_val_cnn'],\n",
    "        processed_data['y_val_5class_onehot'],\n",
    "        error_results,\n",
    "        emotion_map=processed_data['new_emotion_map'],\n",
    "        batch_size=64,\n",
    "        epochs=20\n",
    "    )\n",
    "    \n",
    "    # Visualize refinement history\n",
    "    visualize_training_history(refinement_history, title=\"Model Refinement History\")\n",
    "    \n",
    "    # Evaluate refined model on validation data\n",
    "    val_preds_refined = refined_model.predict(processed_data['X_val_cnn'])\n",
    "    val_preds_refined_class = np.argmax(val_preds_refined, axis=1)\n",
    "    \n",
    "    refined_val_accuracy = np.mean(val_preds_refined_class == val_true_class)\n",
    "    refined_val_report = classification_report(val_true_class, val_preds_refined_class, output_dict=True)\n",
    "    refined_val_conf_matrix = confusion_matrix(val_true_class, val_preds_refined_class)\n",
    "    \n",
    "    print(f\"Refined Model Validation Accuracy: {refined_val_accuracy:.4f}\")\n",
    "    \n",
    "    refined_val_metrics = {\n",
    "        'name': \"Refined Model\",\n",
    "        'accuracy': refined_val_accuracy,\n",
    "        'report': refined_val_report,\n",
    "        'conf_matrix': refined_val_conf_matrix\n",
    "    }\n",
    "    \n",
    "    # Add refined model to comparison\n",
    "    all_val_metrics.append(refined_val_metrics)\n",
    "    models.append(refined_model)\n",
    "    model_names.append(\"Refined Model\")\n",
    "    \n",
    "    # Update best model if refined model is better\n",
    "    if refined_val_accuracy > all_val_metrics[best_model_idx]['accuracy']:\n",
    "        best_model_idx = len(all_val_metrics) - 1  # Index of refined model\n",
    "        best_model_name = \"Refined Model\"\n",
    "        print(f\"Refined model is now the best model with accuracy {refined_val_accuracy:.4f}\")\n",
    "    \n",
    "    # 7. Final Model Selection\n",
    "    print(\"\\n========== 5.7 Final Model Selection ==========\")\n",
    "    \n",
    "    # Select the final model based on validation performance\n",
    "    if best_model_name == \"Ensemble (weighted)\":\n",
    "        # For the final model, we'll use the ensemble prediction function\n",
    "        # But for demonstration, we'll also use the best individual model\n",
    "        best_individual_idx = np.argmax([m['accuracy'] for m in individual_val_metrics])\n",
    "        final_model = models[best_individual_idx]\n",
    "        final_model_name = model_names[best_individual_idx]\n",
    "        \n",
    "        print(f\"Selected final model: {best_model_name} (using {final_model_name} as base)\")\n",
    "        print(\"Note: For full ensemble use in production, would need to save all component models\")\n",
    "    else:\n",
    "        model_idx = model_names.index(best_model_name)\n",
    "        final_model = models[model_idx]\n",
    "        final_model_name = best_model_name\n",
    "        \n",
    "        print(f\"Selected final model: {final_model_name}\")\n",
    "    \n",
    "    # Visualize model predictions on a few validation samples\n",
    "    print(\"\\nVisualizing predictions on validation samples:\")\n",
    "    \n",
    "    sample_indices = np.random.choice(len(processed_data['X_val_cnn']), 10, replace=False)\n",
    "    X_samples = processed_data['X_val_cnn'][sample_indices]\n",
    "    y_samples = np.argmax(processed_data['y_val_5class_onehot'][sample_indices], axis=1)\n",
    "    sample_true_emotions = [processed_data['new_emotion_map'][y] for y in y_samples]\n",
    "    \n",
    "    visualize_model_predictions_on_samples(\n",
    "        final_model,\n",
    "        X_samples,\n",
    "        emotion_map=processed_data['new_emotion_map'],\n",
    "        true_emotions=sample_true_emotions\n",
    "    )\n",
    "    \n",
    "    # Save the final model\n",
    "    preprocessing_info = {\n",
    "        'image_size': (48, 48),\n",
    "        'normalization': 'divide_by_255',\n",
    "        'color_mode': 'grayscale'\n",
    "    }\n",
    "    \n",
    "    model_path = save_and_export_model(\n",
    "        final_model,\n",
    "        f\"emotion_recognition_5class_{final_model_name.replace(' ', '_').lower()}\",\n",
    "        processed_data['new_emotion_map'],\n",
    "        preprocessing_info\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel saved and ready for next section: {model_path} .\")\n",
    "    \n",
    "    # Return comprehensive results\n",
    "    return {\n",
    "        'grid_results': grid_results,\n",
    "        'best_params': best_params,\n",
    "        'cv_results': cv_results,\n",
    "        'transfer_model': fine_tuned_model,\n",
    "        'transfer_val_metrics': transfer_val_metrics,\n",
    "        'individual_models': models,\n",
    "        'individual_model_names': model_names,\n",
    "        'individual_val_metrics': individual_val_metrics,\n",
    "        'ensemble_val_metrics': ensemble_val_metrics,\n",
    "        'error_results': error_results,\n",
    "        'refined_model': refined_model,\n",
    "        'refined_val_metrics': refined_val_metrics,\n",
    "        'all_val_metrics': all_val_metrics,\n",
    "        'final_model': final_model,\n",
    "        'final_model_name': final_model_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "if 'processed_data' in globals():\n",
    "    print(\"Running Section 5 pipeline with preprocessed data...\")\n",
    "    section5_results = run_section5_pipeline(processed_data)\n",
    "else:\n",
    "    print(\"Preprocessed data not found. Please run Sections 1-4 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(processed_data, section5_results):\n",
    "    \"\"\"\n",
    "    Train the final model with extended training parameters and reduced early stopping.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "    from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    \n",
    "    # Define batch size early to avoid reference errors\n",
    "    batch_size = 64\n",
    "    \n",
    "    print(\"\\n========== 6. Final Model Training ==========\")\n",
    "    \n",
    "    # 1. Combine training and validation data\n",
    "    print(\"Combining training and validation data for final model training...\")\n",
    "    \n",
    "    # Combine image data\n",
    "    X_combined = np.concatenate([\n",
    "        processed_data['X_train_aug_cnn'], \n",
    "        processed_data['X_val_cnn']\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Combine labels\n",
    "    y_combined = np.concatenate([\n",
    "        processed_data['y_train_aug_onehot'], \n",
    "        processed_data['y_val_5class_onehot']\n",
    "    ], axis=0)\n",
    "    \n",
    "    print(f\"Combined dataset shape: {X_combined.shape}\")\n",
    "    print(f\"Combined labels shape: {y_combined.shape}\")\n",
    "    \n",
    "    # Calculate class distribution in combined dataset\n",
    "    y_combined_classes = np.argmax(y_combined, axis=1)\n",
    "    class_counts = np.bincount(y_combined_classes)\n",
    "    \n",
    "    print(\"\\nClass distribution in combined dataset:\")\n",
    "    for cls, count in enumerate(class_counts):\n",
    "        print(f\"  Class {cls} ({processed_data['new_emotion_map'][cls]}): {count} samples\")\n",
    "    \n",
    "    # 2. Create a validation split from the combined data\n",
    "    # Using a smaller validation set to have more training data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_combined, \n",
    "        y_combined,\n",
    "        test_size=0.10,  # Use 10% as internal validation set (smaller than before)\n",
    "        stratify=y_combined_classes,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAfter validation split:\")\n",
    "    print(f\"  Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"  Validation set: {X_val.shape[0]} samples\")\n",
    "    \n",
    "    # 3. Create a new model with best hyperparameters\n",
    "    best_params = section5_results['best_params']\n",
    "    print(f\"\\nCreating a new model with best hyperparameters:\")\n",
    "    print(f\"  Learning rate: {best_params['learning_rate']}\")\n",
    "    print(f\"  Optimizer: {best_params['optimizer']}\")\n",
    "    print(f\"  Filters: {best_params['filters']}\")\n",
    "    \n",
    "    # Create CNN model directly\n",
    "    def create_improved_cnn(input_shape=(48, 48, 1), num_classes=5, \n",
    "                            filters=(32, 64, 128), kernel_size=(3, 3), \n",
    "                            dropout_rates=(0.25, 0.25, 0.25, 0.5, 0.5),\n",
    "                            use_batch_norm=True, learning_rate=0.001, \n",
    "                            optimizer_name='adam', l2_reg=0.0001):\n",
    "        \"\"\"\n",
    "        Create an improved CNN model with configurable hyperparameters.\n",
    "        \"\"\"\n",
    "        # Initialize model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # First convolutional block\n",
    "        model.add(Conv2D(filters[0], kernel_size, padding='same', \n",
    "                        activation='relu', input_shape=input_shape,\n",
    "                        kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Conv2D(filters[0], kernel_size, padding='same', \n",
    "                        activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout_rates[0]))\n",
    "        \n",
    "        # Second convolutional block\n",
    "        model.add(Conv2D(filters[1], kernel_size, padding='same', \n",
    "                        activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Conv2D(filters[1], kernel_size, padding='same', \n",
    "                        activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout_rates[1]))\n",
    "        \n",
    "        # Third convolutional block\n",
    "        model.add(Conv2D(filters[2], kernel_size, padding='same', \n",
    "                        activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Conv2D(filters[2], kernel_size, padding='same', \n",
    "                        activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout_rates[2]))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rates[3]))\n",
    "        model.add(Dense(256, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rates[4]))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        \n",
    "        # Select optimizer\n",
    "        if optimizer_name.lower() == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_name.lower() == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        elif optimizer_name.lower() == 'sgd':\n",
    "            optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "        else:\n",
    "            print(f\"Unrecognized optimizer: {optimizer_name}. Using Adam.\")\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # Create model\n",
    "    final_model = create_improved_cnn(\n",
    "        input_shape=processed_data['X_train_cnn'].shape[1:],\n",
    "        num_classes=processed_data['y_train_5class_onehot'].shape[1],\n",
    "        filters=best_params['filters'],\n",
    "        dropout_rates=(0.25, 0.25, 0.25, 0.5, 0.5),\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        optimizer_name=best_params['optimizer']\n",
    "    )\n",
    "    \n",
    "    # 4. Set up class weights similar to the successful Section 5 setup\n",
    "    # Instead of enhancing, we'll use the exact class weights that worked well in Section 5\n",
    "    print(\"Using the exact class weights that worked well in Section 5...\")\n",
    "    \n",
    "    # Use the original class weights \n",
    "    class_weights = processed_data['class_weights']\n",
    "    \n",
    "    # Create directory for checkpoints\n",
    "    if not os.path.exists('./checkpoints'):\n",
    "        os.makedirs('./checkpoints')\n",
    "    \n",
    "    # 5. Define callbacks with much higher patience for early stopping\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath='./checkpoints/best_model.keras',\n",
    "        monitor='val_accuracy',  # Monitor accuracy instead of loss\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=20,  # Much higher patience\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode='max'  # We want to maximize accuracy\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.5,\n",
    "            patience=10,  # Also higher patience for LR reduction\n",
    "            min_lr=1e-6,\n",
    "            verbose=1,\n",
    "            mode='max'  # We want to maximize accuracy\n",
    "        ),\n",
    "        model_checkpoint\n",
    "    ]\n",
    "    \n",
    "    # 6. Train the model with more epochs\n",
    "    print(\"\\nTraining final model on combined dataset...\")\n",
    "    print(\"Using extended training parameters (more epochs, higher patience)...\")\n",
    "    \n",
    "    # Train with more epochs and patience\n",
    "    history = final_model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=100,  # Much more epochs (100 instead of 30)\n",
    "        validation_data=(X_val, y_val),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 7. Try to load the best model from checkpoint\n",
    "    try:\n",
    "        from tensorflow.keras.models import load_model\n",
    "        best_model_path = './checkpoints/best_model.h5'\n",
    "        if os.path.exists(best_model_path):\n",
    "            print(f\"\\nLoading best model from checkpoint: {best_model_path}\")\n",
    "            final_model = load_model(best_model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}\")\n",
    "        print(\"Continuing with current model state\")\n",
    "    \n",
    "    # 8. Visualize training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 9. Evaluate on the validation set\n",
    "    print(\"\\nEvaluating final model on validation data...\")\n",
    "    val_loss, val_accuracy = final_model.evaluate(X_val, y_val, verbose=1)\n",
    "    print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "    \n",
    "    # 10. Save the model\n",
    "    save_dir = 'production_models'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    model_path = os.path.join(save_dir, \"emotion_recognition_5class_final.h5\")\n",
    "    final_model.save(model_path)\n",
    "    \n",
    "    # Save best epoch and accuracy in metadata\n",
    "    best_epoch = np.argmax(history.history['val_accuracy']) + 1\n",
    "    best_accuracy = np.max(history.history['val_accuracy'])\n",
    "    \n",
    "    print(f\"\\nBest validation accuracy: {best_accuracy:.4f} (epoch {best_epoch})\")\n",
    "    print(f\"Final model saved to {model_path}\")\n",
    "    \n",
    "    return {\n",
    "        'final_model': final_model,\n",
    "        'training_history': history,\n",
    "        'model_path': model_path,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_loss': val_loss,\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_accuracy': best_accuracy\n",
    "    }\n",
    "\n",
    "# Run the extended training pipeline\n",
    "if 'section5_results' in globals() and 'processed_data' in globals():\n",
    "    print(\"Running Section 6 pipeline with results from Section 5...\")\n",
    "    section6_results = train_final_model(processed_data, section5_results)\n",
    "else:\n",
    "    print(\"Required data from Section 5 not found. Please run Section 5 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Set Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(final_model, processed_data):\n",
    "    \"\"\"\n",
    "    Evaluate the final model on the test set.\n",
    "    This is the only time the test set is used in the entire pipeline.\n",
    "    \n",
    "    Args:\n",
    "        final_model: The trained final model\n",
    "        processed_data: Dictionary of preprocessed data\n",
    "        \n",
    "    Returns:\n",
    "        Evaluation metrics on test set\n",
    "    \"\"\"\n",
    "    print(\"\\n========== 7.1 FINAL TEST SET EVALUATION ==========\")\n",
    "    print(\"Note: This is the only evaluation on the test set in the entire pipeline\")\n",
    "    \n",
    "    # Get predictions on test set\n",
    "    test_pred = final_model.predict(processed_data['X_test_cnn'])\n",
    "    test_pred_class = np.argmax(test_pred, axis=1)\n",
    "    test_true_class = np.argmax(processed_data['y_test_5class_onehot'], axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_accuracy = np.mean(test_pred_class == test_true_class)\n",
    "    test_report = classification_report(test_true_class, test_pred_class, output_dict=True)\n",
    "    test_conf_matrix = confusion_matrix(test_true_class, test_pred_class)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Final model test accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"\\nClass-wise performance on test set:\")\n",
    "    \n",
    "    # Print class-wise metrics\n",
    "    for i in range(len(processed_data['new_emotion_map'])):\n",
    "        if str(i) in test_report:\n",
    "            class_precision = test_report[str(i)]['precision']\n",
    "            class_recall = test_report[str(i)]['recall']\n",
    "            class_f1 = test_report[str(i)]['f1-score']\n",
    "            class_support = test_report[str(i)]['support']\n",
    "            \n",
    "            print(f\"  Class {i} ({processed_data['new_emotion_map'][i]}): \"\n",
    "                    f\"Precision={class_precision:.4f}, \"\n",
    "                    f\"Recall={class_recall:.4f}, \"\n",
    "                    f\"F1={class_f1:.4f}, \"\n",
    "                    f\"Support={class_support}\")\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    return {\n",
    "        'accuracy': test_accuracy,\n",
    "        'report': test_report,\n",
    "        'conf_matrix': test_conf_matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualize Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test_performance(test_metrics, processed_data, model):\n",
    "    \"\"\"\n",
    "    Visualize the performance on the test set through different visualizations.\n",
    "    \n",
    "    Args:\n",
    "        test_metrics: Test set evaluation metrics\n",
    "        processed_data: Dictionary of preprocessed data\n",
    "        model: The trained model to use for predictions\n",
    "    \"\"\"\n",
    "    print(\"\\n========== 7.2 Test Set Performance Visualization ==========\")\n",
    "    \n",
    "    # Extract data\n",
    "    test_conf_matrix = test_metrics['conf_matrix']\n",
    "    test_report = test_metrics['report']\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(test_conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[processed_data['new_emotion_map'][i] for i in range(len(processed_data['new_emotion_map']))],\n",
    "                yticklabels=[processed_data['new_emotion_map'][i] for i in range(len(processed_data['new_emotion_map']))])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Test Set Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Normalized Confusion Matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    norm_conf_matrix = test_conf_matrix.astype('float') / test_conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(norm_conf_matrix, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=[processed_data['new_emotion_map'][i] for i in range(len(processed_data['new_emotion_map']))],\n",
    "                yticklabels=[processed_data['new_emotion_map'][i] for i in range(len(processed_data['new_emotion_map']))])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Normalized Test Set Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Class-wise Metrics Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Collect class metrics\n",
    "    classes = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for i in range(len(processed_data['new_emotion_map'])):\n",
    "        if str(i) in test_report:\n",
    "            classes.append(processed_data['new_emotion_map'][i])\n",
    "            precision.append(test_report[str(i)]['precision'])\n",
    "            recall.append(test_report[str(i)]['recall'])\n",
    "            f1_scores.append(test_report[str(i)]['f1-score'])\n",
    "    \n",
    "    # Plot class metrics\n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, precision, width, label='Precision', color='skyblue')\n",
    "    plt.bar(x, recall, width, label='Recall', color='salmon')\n",
    "    plt.bar(x + width, f1_scores, width, label='F1-Score', color='lightgreen')\n",
    "    \n",
    "    plt.xlabel('Emotion Class')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Test Set Performance Metrics by Class')\n",
    "    plt.xticks(x, classes, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Sample misclassifications\n",
    "    # Get a few misclassified examples from the test set\n",
    "    test_pred = model.predict(processed_data['X_test_cnn'])\n",
    "    test_pred_class = np.argmax(test_pred, axis=1)\n",
    "    test_true_class = np.argmax(processed_data['y_test_5class_onehot'], axis=1)\n",
    "    \n",
    "    misclassified_indices = np.where(test_pred_class != test_true_class)[0]\n",
    "    \n",
    "    if len(misclassified_indices) > 0:\n",
    "        sample_size = min(10, len(misclassified_indices))\n",
    "        sample_indices = np.random.choice(misclassified_indices, sample_size, replace=False)\n",
    "        \n",
    "        plt.figure(figsize=(15, sample_size))\n",
    "        \n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            plt.imshow(processed_data['X_test_cnn'][idx].reshape(48, 48), cmap='gray')\n",
    "            plt.title(f\"True: {processed_data['new_emotion_map'][test_true_class[idx]]}\\n\" + \n",
    "                      f\"Pred: {processed_data['new_emotion_map'][test_pred_class[idx]]}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No misclassified samples found in the test set (perfect accuracy)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Run Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_section7_pipeline(section6_results, processed_data):\n",
    "    \"\"\"\n",
    "    Run the Section 7 pipeline for final test set evaluation.\n",
    "    \n",
    "    Args:\n",
    "        section6_results: Results from Section 6\n",
    "        processed_data: Dictionary of preprocessed data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of test evaluation results\n",
    "    \"\"\"\n",
    "    print(\"\\n========== 7. Final Test Set Evaluation ==========\")\n",
    "    \n",
    "    # 1. Test set evaluation\n",
    "    test_metrics = evaluate_on_test_set(section6_results['final_model'], processed_data)\n",
    "    \n",
    "    # 2. Visualize test set performance\n",
    "    visualize_test_performance(test_metrics, processed_data)\n",
    "    \n",
    "    print(\"\\nFinal test set evaluation complete!\")\n",
    "    print(f\"Final test accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'test_metrics': test_metrics,\n",
    "        'final_model': section6_results['final_model']  # Include the model for reference\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Execute Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this after Section 6 is complete and you're ready for final evaluation\n",
    "if 'section6_results' in globals() and 'processed_data' in globals():\n",
    "    print(\"Running final test set evaluation...\")\n",
    "    section7_results = run_section7_pipeline(section6_results, processed_data)\n",
    "else:\n",
    "    print(\"Section 6 results or processed data not found. Please run previous sections first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask opencv-python tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# Load model and metadata\n",
    "model = tf.keras.models.load_model('emotion_recognition_5class_final.h5')\n",
    "with open('emotion_recognition_5class_final_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    image = cv2.resize(image, (48, 48))\n",
    "    if len(image.shape) == 3 and image.shape[2] > 1:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image / 255.0\n",
    "    image = image.reshape(1, 48, 48, 1)\n",
    "    return image\n",
    "\n",
    "# Softer, modern color palette for emotions\n",
    "emotion_colors = {\n",
    "    \"Engaged\": (102, 204, 153),        \n",
    "    \"Frustrated\": (102, 102, 255),       \n",
    "    \"Disengaged\": (255, 153, 153),    # blue (unchanged)\n",
    "    \"Surprise\": (0, 215, 255),        # yellow (unchanged)\n",
    "    \"Neutral\": (128, 128, 128)        # gray (darker gray)\n",
    "}\n",
    "\n",
    "# Smoothing buffer\n",
    "prediction_buffer = deque(maxlen=10)\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Haar Cascade face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        processed_img = preprocess_image(face_img)\n",
    "\n",
    "        # Predict and smooth\n",
    "        raw_preds = model.predict(processed_img)[0]\n",
    "        prediction_buffer.append(raw_preds)\n",
    "        avg_preds = np.mean(prediction_buffer, axis=0)\n",
    "\n",
    "        pred_class = np.argmax(avg_preds)\n",
    "        emotion = metadata['emotion_map'][str(pred_class)]\n",
    "        confidence = float(avg_preds[pred_class])\n",
    "\n",
    "        # Draw bounding box\n",
    "        box_color = emotion_colors.get(emotion, (255, 255, 255))\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), box_color, 2)\n",
    "\n",
    "        # Draw label above face\n",
    "        label = f'{emotion}'\n",
    "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.9, box_color, 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # Progress bars beside the face\n",
    "        bar_x = x + w + 10\n",
    "        bar_y = y\n",
    "        bar_width = 50\n",
    "        bar_height = h // len(metadata['emotion_map'])\n",
    "\n",
    "        for i, (key, name) in enumerate(metadata['emotion_map'].items()):\n",
    "            prob = avg_preds[int(key)]\n",
    "            bar_length = int(prob * bar_width)\n",
    "            color = emotion_colors.get(name, (255, 255, 255))\n",
    "            y_pos = bar_y + i * bar_height\n",
    "\n",
    "            # Background bar (light gray)\n",
    "            cv2.rectangle(frame, (bar_x, y_pos),\n",
    "                          (bar_x + bar_width, y_pos + bar_height - 4),\n",
    "                          (230, 230, 230), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # Colored progress bar\n",
    "            cv2.rectangle(frame, (bar_x, y_pos),\n",
    "                          (bar_x + bar_length, y_pos + bar_height - 4),\n",
    "                          color, -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # Drop shadow text\n",
    "            cv2.putText(frame, name, (bar_x + bar_width + 6, y_pos + bar_height - 6),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.42, (50, 50, 50), 2, lineType=cv2.LINE_AA)\n",
    "            # Main text\n",
    "            cv2.putText(frame, name, (bar_x + bar_width + 6, y_pos + bar_height - 6),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.42, color, 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Display window\n",
    "    cv2.imshow('Emotion Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyWindow('Emotion Recognition')\n",
    "cv2.waitKey(1)\n",
    "time.sleep(0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
